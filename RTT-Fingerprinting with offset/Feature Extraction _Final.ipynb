{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb67633a",
   "metadata": {},
   "source": [
    "**1. Importing necessary libraries and combining no. of CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "839db798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#combining no of csv file into one file with name combine_csv\n",
    "#os.chdir('D:\\Final')\n",
    "os.chdir(r'C:\\Users\\LILA\\Desktop\\RTT-FIngerprinting-with-offset\\RTT-Fingerprinting with offset\\Dataset\\with_Offset')\n",
    "extension='csv'\n",
    "\n",
    "all_filenames=[i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "combined_csv=pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "df=combined_csv\n",
    "df.drop(['AP1RSS','AP2RSS','AP3RSS','True_range1','True_range2','True_range3','x1','x2','x3','y1','y2','y3'],axis=1,inplace=True)\n",
    "#dff=df.assign(Product_RTT=df['AP1RTT']*df['AP2RTT']*df['AP3RTT'],Product_RTT12=df['AP1RTT']*df['AP2RTT'],Product_RTT23=df['AP2RTT']*df['AP3RTT'],Product_RTT13=df['AP1RTT']*df['AP3RTT'],square_RTT1=df['AP1RTT']*df['AP1RTT'],square_RTT2=df['AP2RTT']*df['AP2RTT'],square_RTT3=df['AP3RTT']*df['AP3RTT'])\n",
    "dff=df.assign(Product_RTT=df['AP1RTT']*df['AP2RTT']*df['AP3RTT'],Product_RTT12=df['AP1RTT']*df['AP2RTT'],Product_RTT23=df['AP2RTT']*df['AP3RTT'],Product_RTT13=df['AP1RTT']*df['AP3RTT'])\n",
    "# Group the DataFrame by 'x' and 'y'\n",
    "groups = dff.groupby(['x', 'y'])\n",
    "\n",
    "# Split the groups into two separate dataframes\n",
    "df1 = pd.concat([group.iloc[:len(group) // 2] for _, group in groups])\n",
    "df2 = pd.concat([group.iloc[len(group) // 2:] for _, group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1b840cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1RTTA</th>\n",
       "      <th>AP1STDEVA</th>\n",
       "      <th>AP2RTTA</th>\n",
       "      <th>AP2STDEVA</th>\n",
       "      <th>AP3RTTA</th>\n",
       "      <th>AP3STDEVA</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Product_RTTA</th>\n",
       "      <th>Product_RTT12A</th>\n",
       "      <th>Product_RTT23</th>\n",
       "      <th>Product_RTT13A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.770082</td>\n",
       "      <td>0.145</td>\n",
       "      <td>6.115656</td>\n",
       "      <td>0.150</td>\n",
       "      <td>7.698439</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>554.147283</td>\n",
       "      <td>71.981772</td>\n",
       "      <td>47.081003</td>\n",
       "      <td>90.611260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.283082</td>\n",
       "      <td>0.407</td>\n",
       "      <td>6.145656</td>\n",
       "      <td>0.267</td>\n",
       "      <td>7.659439</td>\n",
       "      <td>0.425</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>531.120362</td>\n",
       "      <td>69.341940</td>\n",
       "      <td>47.072276</td>\n",
       "      <td>86.422080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.067082</td>\n",
       "      <td>0.245</td>\n",
       "      <td>6.428656</td>\n",
       "      <td>0.630</td>\n",
       "      <td>7.894439</td>\n",
       "      <td>0.414</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>561.661412</td>\n",
       "      <td>71.146463</td>\n",
       "      <td>50.750631</td>\n",
       "      <td>87.368406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.130082</td>\n",
       "      <td>0.864</td>\n",
       "      <td>5.803656</td>\n",
       "      <td>0.210</td>\n",
       "      <td>8.401439</td>\n",
       "      <td>1.739</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>493.933294</td>\n",
       "      <td>58.791511</td>\n",
       "      <td>48.759060</td>\n",
       "      <td>85.107268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.946082</td>\n",
       "      <td>0.252</td>\n",
       "      <td>6.194656</td>\n",
       "      <td>0.105</td>\n",
       "      <td>7.620439</td>\n",
       "      <td>0.513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>563.926722</td>\n",
       "      <td>74.001868</td>\n",
       "      <td>47.205997</td>\n",
       "      <td>91.034391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1.194914</td>\n",
       "      <td>0.271</td>\n",
       "      <td>8.179640</td>\n",
       "      <td>0.152</td>\n",
       "      <td>5.990282</td>\n",
       "      <td>1.101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>58.548811</td>\n",
       "      <td>9.773966</td>\n",
       "      <td>48.998353</td>\n",
       "      <td>7.157871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.350914</td>\n",
       "      <td>0.146</td>\n",
       "      <td>8.179640</td>\n",
       "      <td>0.154</td>\n",
       "      <td>5.932282</td>\n",
       "      <td>1.149</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>65.551655</td>\n",
       "      <td>11.049989</td>\n",
       "      <td>48.523934</td>\n",
       "      <td>8.014002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.359914</td>\n",
       "      <td>0.412</td>\n",
       "      <td>8.238640</td>\n",
       "      <td>0.110</td>\n",
       "      <td>6.049282</td>\n",
       "      <td>1.107</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>67.775196</td>\n",
       "      <td>11.203841</td>\n",
       "      <td>49.837859</td>\n",
       "      <td>8.226503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.350914</td>\n",
       "      <td>0.211</td>\n",
       "      <td>8.121640</td>\n",
       "      <td>0.148</td>\n",
       "      <td>6.049282</td>\n",
       "      <td>1.129</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>66.370524</td>\n",
       "      <td>10.971636</td>\n",
       "      <td>49.130093</td>\n",
       "      <td>8.172059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1.194914</td>\n",
       "      <td>0.261</td>\n",
       "      <td>8.121640</td>\n",
       "      <td>0.097</td>\n",
       "      <td>5.990282</td>\n",
       "      <td>1.137</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>58.133655</td>\n",
       "      <td>9.704661</td>\n",
       "      <td>48.650916</td>\n",
       "      <td>7.157871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14005 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AP1RTTA  AP1STDEVA   AP2RTTA  AP2STDEVA   AP3RTTA  AP3STDEVA  x  y  \\\n",
       "0    11.770082      0.145  6.115656      0.150  7.698439      0.372  1  1   \n",
       "1    11.283082      0.407  6.145656      0.267  7.659439      0.425  1  1   \n",
       "2    11.067082      0.245  6.428656      0.630  7.894439      0.414  1  1   \n",
       "3    10.130082      0.864  5.803656      0.210  8.401439      1.739  1  1   \n",
       "4    11.946082      0.252  6.194656      0.105  7.620439      0.513  1  1   \n",
       "..         ...        ...       ...        ...       ...        ... .. ..   \n",
       "327   1.194914      0.271  8.179640      0.152  5.990282      1.101  6  8   \n",
       "328   1.350914      0.146  8.179640      0.154  5.932282      1.149  6  8   \n",
       "329   1.359914      0.412  8.238640      0.110  6.049282      1.107  6  8   \n",
       "330   1.350914      0.211  8.121640      0.148  6.049282      1.129  6  8   \n",
       "331   1.194914      0.261  8.121640      0.097  5.990282      1.137  6  8   \n",
       "\n",
       "     Product_RTTA  Product_RTT12A  Product_RTT23  Product_RTT13A  \n",
       "0      554.147283       71.981772      47.081003       90.611260  \n",
       "1      531.120362       69.341940      47.072276       86.422080  \n",
       "2      561.661412       71.146463      50.750631       87.368406  \n",
       "3      493.933294       58.791511      48.759060       85.107268  \n",
       "4      563.926722       74.001868      47.205997       91.034391  \n",
       "..            ...             ...            ...             ...  \n",
       "327     58.548811        9.773966      48.998353        7.157871  \n",
       "328     65.551655       11.049989      48.523934        8.014002  \n",
       "329     67.775196       11.203841      49.837859        8.226503  \n",
       "330     66.370524       10.971636      49.130093        8.172059  \n",
       "331     58.133655        9.704661      48.650916        7.157871  \n",
       "\n",
       "[14005 rows x 12 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_name={'AP1RTT':'AP1RTTA','AP1STDEV':'AP1STDEVA','AP2RTT':'AP2RTTA','AP2STDEV':'AP2STDEVA','AP3RTT':'AP3RTTA','AP3STDEV':'AP3STDEVA','Product_RTT':'Product_RTTA','Product_RTT12':'Product_RTT12A','Product_RTT13':'Product_RTT13A','square_RTT1':'square_RTT1A','square_RTT2':'square_RTT2A','square_RTT3':'square_RTT3A'}\n",
    "df1.rename(columns=new_name,inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2df627df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTT':'AP1RTTB','AP1STDEV':'AP1STDEVB','AP2RTT':'AP2RTTB','AP2STDEV':'AP2STDEVB','AP3RTT':'AP3RTTB','AP3STDEV':'AP3STDEVB','Product_RTT':'Product_RTTB','Product_RTT12':'Product_RTT12B','Product_RTT13':'Product_RTT13B','square_RTT1':'square_RTT1B','square_RTT2':'square_RTT2B','square_RTT3':'square_RTT3B'}\n",
    "df2.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b8d0102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by x and y values, and calculate the mean of each group\n",
    "groupedd1 = df1.groupby(['x', 'y']).mean()\n",
    "groupedd2 = df2.groupby(['x', 'y']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d5d47f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'x' and 'y', and calculate the minimum, maximum, 25th, 50th, and 75th percentiles for each column for local feature extractions\n",
    "\n",
    "grouped = df1.groupby(['x', 'y']).agg(['min', 'max', lambda x: np.percentile(x, q=25), lambda x: np.percentile(x, q=50), lambda x: np.percentile(x, q=75)])\n",
    "\n",
    "# Add the mean or average value of each column to the grouped dataframe\n",
    "grouped_mean = df1.groupby(['x', 'y']).mean()\n",
    "grouped = pd.concat([grouped, grouped_mean], axis=1)\n",
    "\n",
    "# Rename the columns and reset the index\n",
    "grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
    "grouped = grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1178b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'x' and 'y', and calculate the minimum, maximum, 25th, 50th, and 75th percentiles for each column for local feature extractions\n",
    "\n",
    "groupedd = df2.groupby(['x', 'y']).agg(['min', 'max', lambda x: np.percentile(x, q=25), lambda x: np.percentile(x, q=50), lambda x: np.percentile(x, q=75)])\n",
    "\n",
    "# Add the mean or average value of each column to the grouped dataframe\n",
    "grouped_mean = df2.groupby(['x', 'y']).mean()\n",
    "groupedd = pd.concat([groupedd, grouped_mean], axis=1)\n",
    "\n",
    "# Rename the columns and reset the index\n",
    "groupedd.columns = ['_'.join(col).strip() for col in groupedd.columns.values]\n",
    "groupedd = groupedd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4b0d87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTTA_<lambda_0>': 'AP1RTTA_25','AP2RTTA_<lambda_0>': 'AP2RTTA_25','AP3RTTA_<lambda_0>': 'AP3RTTA_25',\n",
    "          'AP1RTTA_<lambda_1>': 'AP1RTTA_50','AP2RTTA_<lambda_1>': 'AP2RTTA_50','AP3RTTA_<lambda_1>': 'AP3RTTA_50',\n",
    "          'AP1RTTA_<lambda_2>': 'AP1RTTA_75','AP2RTTA_<lambda_2>': 'AP2RTTA_75','AP3RTTA_<lambda_2>': 'AP3RTTA_75',\n",
    "           \n",
    "             \n",
    "          'AP1STDEVA_<lambda_0>':'AP1STDEVA_25','AP2STDEVA_<lambda_0>':'AP2STDEVA_25','AP3STDEVA_<lambda_0>':'AP3STDEVA_25',\n",
    "          'AP1STDEVA_<lambda_1>':'AP1STDEVA_50','AP2STDEVA_<lambda_1>':'AP2STDEVA_50','AP3STDEVA_<lambda_1>':'AP3STDEVA_50',\n",
    "          'AP1STDEVA_<lambda_2>':'AP1STDEVA_75','AP2STDEVA_<lambda_2>':'AP2STDEVA_75','AP3STDEVA_<lambda_2>':'AP3STDEVA_75',\n",
    "          'A_P_1_R_T_T_A':'AP1RTTA_MEAN','A_P_2_R_T_T_A':'AP2RTTA_MEAN','A_P_3_R_T_T_A_A':'AP3RTTA_MEAN',\n",
    "          'A_P_1_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_2_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_3_S_T_D_E_V_A':'AP1STDEVA_MEAN'}\n",
    "grouped.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "706766ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTTB_<lambda_0>': 'AP1RTTB_25','AP2RTTB_<lambda_0>': 'AP2RTTB_25','AP3RTTB_<lambda_0>': 'AP3RTTB_25',\n",
    "          'AP1RTTB_<lambda_1>': 'AP1RTTB_50','AP2RTTB_<lambda_1>': 'AP2RTTB_50','AP3RTTB_<lambda_1>': 'AP3RTTB_50',\n",
    "          'AP1RTTB_<lambda_2>': 'AP1RTTB_75','AP2RTTB_<lambda_2>': 'AP2RTTB_75','AP3RTTB_<lambda_2>': 'AP3RTTB_75',\n",
    "           \n",
    "             \n",
    "          'AP1STDEVB_<lambda_0>':'AP1STDEVB_25','AP2STDEVB_<lambda_0>':'AP2STDEVB_25','AP3STDEVB_<lambda_0>':'AP3STDEVB_25',\n",
    "          'AP1STDEVB_<lambda_1>':'AP1STDEVB_50','AP2STDEVB_<lambda_1>':'AP2STDEVB_50','AP3STDEVB_<lambda_1>':'AP3STDEVB_50',\n",
    "          'AP1STDEVB_<lambda_2>':'AP1STDEVB_75','AP2STDEVB_<lambda_2>':'AP2STDEVB_75','AP3STDEVB_<lambda_2>':'AP3STDEVB_75',\n",
    "          'A_P_1_R_T_T_A':'AP1RTTA_MEAN','A_P_2_R_T_T_A':'AP2RTTA_MEAN','A_P_3_R_T_T_A_A':'AP3RTTA_MEAN',\n",
    "          'A_P_1_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_2_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_3_S_T_D_E_V_A':'AP1STDEVA_MEAN'}\n",
    "groupedd.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "272580d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1RTTA_min</th>\n",
       "      <th>AP1RTTA_max</th>\n",
       "      <th>AP1RTTA_25</th>\n",
       "      <th>AP1RTTA_50</th>\n",
       "      <th>AP1RTTA_75</th>\n",
       "      <th>AP1STDEVA_min</th>\n",
       "      <th>AP1STDEVA_max</th>\n",
       "      <th>AP1STDEVA_25</th>\n",
       "      <th>AP1STDEVA_50</th>\n",
       "      <th>AP1STDEVA_75</th>\n",
       "      <th>...</th>\n",
       "      <th>A_P_1_R_T_T_B</th>\n",
       "      <th>A_P_1_S_T_D_E_V_B</th>\n",
       "      <th>A_P_2_R_T_T_B</th>\n",
       "      <th>A_P_2_S_T_D_E_V_B</th>\n",
       "      <th>A_P_3_R_T_T_B</th>\n",
       "      <th>A_P_3_S_T_D_E_V_B</th>\n",
       "      <th>P_r_o_d_u_c_t___R_T_T_B</th>\n",
       "      <th>P_r_o_d_u_c_t___R_T_T_1_2_B</th>\n",
       "      <th>P_r_o_d_u_c_t___R_T_T_2_3</th>\n",
       "      <th>P_r_o_d_u_c_t___R_T_T_1_3_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192082</td>\n",
       "      <td>12.180082</td>\n",
       "      <td>9.807082</td>\n",
       "      <td>10.071082</td>\n",
       "      <td>10.364082</td>\n",
       "      <td>0.124</td>\n",
       "      <td>2.368</td>\n",
       "      <td>0.90200</td>\n",
       "      <td>1.0420</td>\n",
       "      <td>1.15100</td>\n",
       "      <td>...</td>\n",
       "      <td>9.860985</td>\n",
       "      <td>1.116149</td>\n",
       "      <td>6.076388</td>\n",
       "      <td>0.144283</td>\n",
       "      <td>8.066601</td>\n",
       "      <td>0.136864</td>\n",
       "      <td>483.355744</td>\n",
       "      <td>59.918953</td>\n",
       "      <td>49.015791</td>\n",
       "      <td>79.546866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.977884</td>\n",
       "      <td>9.831884</td>\n",
       "      <td>9.167884</td>\n",
       "      <td>9.196884</td>\n",
       "      <td>9.255884</td>\n",
       "      <td>0.122</td>\n",
       "      <td>2.568</td>\n",
       "      <td>0.26200</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.34000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.230879</td>\n",
       "      <td>0.424747</td>\n",
       "      <td>6.282222</td>\n",
       "      <td>0.510474</td>\n",
       "      <td>7.077682</td>\n",
       "      <td>0.443328</td>\n",
       "      <td>410.422222</td>\n",
       "      <td>57.989021</td>\n",
       "      <td>44.462794</td>\n",
       "      <td>65.333477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.095074</td>\n",
       "      <td>8.877074</td>\n",
       "      <td>8.451074</td>\n",
       "      <td>8.544074</td>\n",
       "      <td>8.642074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.43600</td>\n",
       "      <td>...</td>\n",
       "      <td>8.431657</td>\n",
       "      <td>0.286670</td>\n",
       "      <td>6.606535</td>\n",
       "      <td>0.814729</td>\n",
       "      <td>6.086084</td>\n",
       "      <td>0.390941</td>\n",
       "      <td>339.107072</td>\n",
       "      <td>55.709792</td>\n",
       "      <td>40.214378</td>\n",
       "      <td>51.315477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.067432</td>\n",
       "      <td>7.991432</td>\n",
       "      <td>6.224432</td>\n",
       "      <td>6.302432</td>\n",
       "      <td>6.380432</td>\n",
       "      <td>0.306</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.83100</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.95200</td>\n",
       "      <td>...</td>\n",
       "      <td>6.310012</td>\n",
       "      <td>0.893827</td>\n",
       "      <td>9.223969</td>\n",
       "      <td>0.799677</td>\n",
       "      <td>2.234744</td>\n",
       "      <td>0.142254</td>\n",
       "      <td>130.063303</td>\n",
       "      <td>58.203495</td>\n",
       "      <td>20.613175</td>\n",
       "      <td>14.100569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.905337</td>\n",
       "      <td>7.274337</td>\n",
       "      <td>6.063337</td>\n",
       "      <td>6.180337</td>\n",
       "      <td>6.258337</td>\n",
       "      <td>0.085</td>\n",
       "      <td>2.070</td>\n",
       "      <td>0.27450</td>\n",
       "      <td>0.3640</td>\n",
       "      <td>0.45700</td>\n",
       "      <td>...</td>\n",
       "      <td>6.049487</td>\n",
       "      <td>0.495289</td>\n",
       "      <td>9.939359</td>\n",
       "      <td>0.351382</td>\n",
       "      <td>1.413777</td>\n",
       "      <td>0.984149</td>\n",
       "      <td>85.000437</td>\n",
       "      <td>60.123097</td>\n",
       "      <td>14.053020</td>\n",
       "      <td>8.551983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.337477</td>\n",
       "      <td>10.073477</td>\n",
       "      <td>9.330477</td>\n",
       "      <td>9.418477</td>\n",
       "      <td>9.535477</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.263</td>\n",
       "      <td>0.45600</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.98950</td>\n",
       "      <td>...</td>\n",
       "      <td>9.466362</td>\n",
       "      <td>0.705821</td>\n",
       "      <td>5.016889</td>\n",
       "      <td>1.094408</td>\n",
       "      <td>8.184383</td>\n",
       "      <td>0.573785</td>\n",
       "      <td>388.937806</td>\n",
       "      <td>47.508577</td>\n",
       "      <td>41.073349</td>\n",
       "      <td>77.473724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.385924</td>\n",
       "      <td>9.496924</td>\n",
       "      <td>8.558924</td>\n",
       "      <td>8.715924</td>\n",
       "      <td>8.773924</td>\n",
       "      <td>0.234</td>\n",
       "      <td>2.606</td>\n",
       "      <td>0.75300</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.600833</td>\n",
       "      <td>0.816597</td>\n",
       "      <td>5.375125</td>\n",
       "      <td>0.214925</td>\n",
       "      <td>7.659420</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>353.903410</td>\n",
       "      <td>46.230158</td>\n",
       "      <td>41.169387</td>\n",
       "      <td>65.843040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.704424</td>\n",
       "      <td>8.903424</td>\n",
       "      <td>7.656424</td>\n",
       "      <td>7.773424</td>\n",
       "      <td>7.861424</td>\n",
       "      <td>0.138</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0.58200</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>0.71100</td>\n",
       "      <td>...</td>\n",
       "      <td>7.881820</td>\n",
       "      <td>0.618753</td>\n",
       "      <td>5.846336</td>\n",
       "      <td>1.605957</td>\n",
       "      <td>6.046766</td>\n",
       "      <td>1.708095</td>\n",
       "      <td>278.653268</td>\n",
       "      <td>46.081722</td>\n",
       "      <td>35.352036</td>\n",
       "      <td>47.660037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.962147</td>\n",
       "      <td>6.609147</td>\n",
       "      <td>5.114147</td>\n",
       "      <td>5.622147</td>\n",
       "      <td>6.130147</td>\n",
       "      <td>0.067</td>\n",
       "      <td>3.159</td>\n",
       "      <td>0.26400</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.72100</td>\n",
       "      <td>...</td>\n",
       "      <td>5.195255</td>\n",
       "      <td>0.737088</td>\n",
       "      <td>8.582743</td>\n",
       "      <td>0.745549</td>\n",
       "      <td>2.833381</td>\n",
       "      <td>0.200416</td>\n",
       "      <td>126.394474</td>\n",
       "      <td>44.610483</td>\n",
       "      <td>24.318763</td>\n",
       "      <td>14.719288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.266863</td>\n",
       "      <td>5.977863</td>\n",
       "      <td>4.961863</td>\n",
       "      <td>5.185863</td>\n",
       "      <td>5.352863</td>\n",
       "      <td>0.069</td>\n",
       "      <td>2.312</td>\n",
       "      <td>0.28900</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.49500</td>\n",
       "      <td>...</td>\n",
       "      <td>5.046985</td>\n",
       "      <td>0.474463</td>\n",
       "      <td>9.446476</td>\n",
       "      <td>0.147662</td>\n",
       "      <td>2.166277</td>\n",
       "      <td>1.417366</td>\n",
       "      <td>103.272514</td>\n",
       "      <td>47.676535</td>\n",
       "      <td>20.462292</td>\n",
       "      <td>10.933095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.561542</td>\n",
       "      <td>15.603542</td>\n",
       "      <td>8.005542</td>\n",
       "      <td>8.137542</td>\n",
       "      <td>9.089042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.385</td>\n",
       "      <td>0.17600</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>1.70400</td>\n",
       "      <td>...</td>\n",
       "      <td>8.166073</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>4.177263</td>\n",
       "      <td>1.994493</td>\n",
       "      <td>8.210008</td>\n",
       "      <td>1.630470</td>\n",
       "      <td>280.448788</td>\n",
       "      <td>34.116598</td>\n",
       "      <td>34.306506</td>\n",
       "      <td>67.106783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.556247</td>\n",
       "      <td>11.579247</td>\n",
       "      <td>7.908247</td>\n",
       "      <td>7.986247</td>\n",
       "      <td>8.064247</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.551</td>\n",
       "      <td>0.95800</td>\n",
       "      <td>1.0960</td>\n",
       "      <td>1.29300</td>\n",
       "      <td>...</td>\n",
       "      <td>8.023966</td>\n",
       "      <td>1.174695</td>\n",
       "      <td>4.463235</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>7.589972</td>\n",
       "      <td>0.548664</td>\n",
       "      <td>271.805883</td>\n",
       "      <td>35.813395</td>\n",
       "      <td>33.875094</td>\n",
       "      <td>60.899231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.019841</td>\n",
       "      <td>8.563841</td>\n",
       "      <td>7.186841</td>\n",
       "      <td>7.274841</td>\n",
       "      <td>7.391841</td>\n",
       "      <td>0.053</td>\n",
       "      <td>3.135</td>\n",
       "      <td>0.98200</td>\n",
       "      <td>1.1280</td>\n",
       "      <td>1.36650</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136196</td>\n",
       "      <td>1.417582</td>\n",
       "      <td>4.929161</td>\n",
       "      <td>1.818303</td>\n",
       "      <td>6.741920</td>\n",
       "      <td>0.204503</td>\n",
       "      <td>237.158760</td>\n",
       "      <td>35.176701</td>\n",
       "      <td>33.231540</td>\n",
       "      <td>48.112409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.733167</td>\n",
       "      <td>9.927167</td>\n",
       "      <td>6.007167</td>\n",
       "      <td>6.085167</td>\n",
       "      <td>6.163167</td>\n",
       "      <td>0.146</td>\n",
       "      <td>3.841</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>1.8560</td>\n",
       "      <td>1.95700</td>\n",
       "      <td>...</td>\n",
       "      <td>6.332151</td>\n",
       "      <td>1.955949</td>\n",
       "      <td>5.601575</td>\n",
       "      <td>0.646799</td>\n",
       "      <td>5.823453</td>\n",
       "      <td>0.311985</td>\n",
       "      <td>206.599372</td>\n",
       "      <td>35.469037</td>\n",
       "      <td>32.633655</td>\n",
       "      <td>36.870458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.431671</td>\n",
       "      <td>12.126671</td>\n",
       "      <td>5.582671</td>\n",
       "      <td>5.670671</td>\n",
       "      <td>5.738671</td>\n",
       "      <td>0.085</td>\n",
       "      <td>4.276</td>\n",
       "      <td>0.35400</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.76950</td>\n",
       "      <td>...</td>\n",
       "      <td>5.661170</td>\n",
       "      <td>0.647979</td>\n",
       "      <td>6.422623</td>\n",
       "      <td>0.200123</td>\n",
       "      <td>5.063792</td>\n",
       "      <td>1.113446</td>\n",
       "      <td>184.101597</td>\n",
       "      <td>36.361424</td>\n",
       "      <td>32.519960</td>\n",
       "      <td>28.665773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.439721</td>\n",
       "      <td>5.611721</td>\n",
       "      <td>4.850721</td>\n",
       "      <td>4.937721</td>\n",
       "      <td>5.133721</td>\n",
       "      <td>0.086</td>\n",
       "      <td>2.425</td>\n",
       "      <td>1.01200</td>\n",
       "      <td>1.1370</td>\n",
       "      <td>1.23900</td>\n",
       "      <td>...</td>\n",
       "      <td>5.021261</td>\n",
       "      <td>1.174977</td>\n",
       "      <td>7.193062</td>\n",
       "      <td>0.311783</td>\n",
       "      <td>4.234446</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>152.932555</td>\n",
       "      <td>36.116293</td>\n",
       "      <td>30.458590</td>\n",
       "      <td>21.262297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.760518</td>\n",
       "      <td>5.045518</td>\n",
       "      <td>4.459518</td>\n",
       "      <td>4.605518</td>\n",
       "      <td>4.722518</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.968</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.26400</td>\n",
       "      <td>...</td>\n",
       "      <td>4.420129</td>\n",
       "      <td>0.342574</td>\n",
       "      <td>8.055034</td>\n",
       "      <td>0.271413</td>\n",
       "      <td>3.604764</td>\n",
       "      <td>0.331555</td>\n",
       "      <td>128.332748</td>\n",
       "      <td>35.603678</td>\n",
       "      <td>29.036511</td>\n",
       "      <td>15.932252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.386816</td>\n",
       "      <td>8.343816</td>\n",
       "      <td>3.931316</td>\n",
       "      <td>4.082816</td>\n",
       "      <td>4.277816</td>\n",
       "      <td>0.111</td>\n",
       "      <td>2.365</td>\n",
       "      <td>0.89900</td>\n",
       "      <td>1.0640</td>\n",
       "      <td>1.19850</td>\n",
       "      <td>...</td>\n",
       "      <td>4.137761</td>\n",
       "      <td>1.023094</td>\n",
       "      <td>8.933132</td>\n",
       "      <td>0.292603</td>\n",
       "      <td>3.166994</td>\n",
       "      <td>0.646008</td>\n",
       "      <td>117.163382</td>\n",
       "      <td>36.994278</td>\n",
       "      <td>28.292315</td>\n",
       "      <td>13.104033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.123260</td>\n",
       "      <td>11.276260</td>\n",
       "      <td>8.434260</td>\n",
       "      <td>8.552260</td>\n",
       "      <td>8.610260</td>\n",
       "      <td>0.444</td>\n",
       "      <td>3.063</td>\n",
       "      <td>1.20600</td>\n",
       "      <td>1.2940</td>\n",
       "      <td>1.36700</td>\n",
       "      <td>...</td>\n",
       "      <td>8.546879</td>\n",
       "      <td>1.370246</td>\n",
       "      <td>3.127473</td>\n",
       "      <td>1.179244</td>\n",
       "      <td>8.939227</td>\n",
       "      <td>0.805656</td>\n",
       "      <td>238.937435</td>\n",
       "      <td>26.730886</td>\n",
       "      <td>27.955577</td>\n",
       "      <td>76.401680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.555143</td>\n",
       "      <td>8.625143</td>\n",
       "      <td>7.556143</td>\n",
       "      <td>7.634143</td>\n",
       "      <td>7.751143</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.984</td>\n",
       "      <td>1.06975</td>\n",
       "      <td>1.1530</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>...</td>\n",
       "      <td>7.619604</td>\n",
       "      <td>1.195492</td>\n",
       "      <td>3.612889</td>\n",
       "      <td>0.340747</td>\n",
       "      <td>8.073302</td>\n",
       "      <td>0.518209</td>\n",
       "      <td>222.247748</td>\n",
       "      <td>27.528392</td>\n",
       "      <td>29.168056</td>\n",
       "      <td>61.515882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.752093</td>\n",
       "      <td>13.622093</td>\n",
       "      <td>6.552093</td>\n",
       "      <td>6.669093</td>\n",
       "      <td>6.786093</td>\n",
       "      <td>0.057</td>\n",
       "      <td>3.289</td>\n",
       "      <td>0.14200</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.44200</td>\n",
       "      <td>...</td>\n",
       "      <td>6.748636</td>\n",
       "      <td>0.470111</td>\n",
       "      <td>4.219492</td>\n",
       "      <td>0.418374</td>\n",
       "      <td>7.209123</td>\n",
       "      <td>0.205618</td>\n",
       "      <td>205.278209</td>\n",
       "      <td>28.475320</td>\n",
       "      <td>30.419221</td>\n",
       "      <td>48.650218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.654699</td>\n",
       "      <td>6.736699</td>\n",
       "      <td>5.769699</td>\n",
       "      <td>5.857699</td>\n",
       "      <td>5.945699</td>\n",
       "      <td>0.526</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.73850</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.90350</td>\n",
       "      <td>...</td>\n",
       "      <td>5.818171</td>\n",
       "      <td>0.916813</td>\n",
       "      <td>5.074313</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>6.428407</td>\n",
       "      <td>2.137917</td>\n",
       "      <td>190.009299</td>\n",
       "      <td>29.523807</td>\n",
       "      <td>32.652754</td>\n",
       "      <td>37.406612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.167443</td>\n",
       "      <td>3.722443</td>\n",
       "      <td>3.214443</td>\n",
       "      <td>3.272443</td>\n",
       "      <td>3.331443</td>\n",
       "      <td>0.106</td>\n",
       "      <td>3.341</td>\n",
       "      <td>0.75925</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>1.17375</td>\n",
       "      <td>...</td>\n",
       "      <td>3.138518</td>\n",
       "      <td>0.825395</td>\n",
       "      <td>8.550370</td>\n",
       "      <td>1.653500</td>\n",
       "      <td>4.119504</td>\n",
       "      <td>0.355508</td>\n",
       "      <td>110.557948</td>\n",
       "      <td>26.834388</td>\n",
       "      <td>35.223354</td>\n",
       "      <td>12.930698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.801157</td>\n",
       "      <td>8.514157</td>\n",
       "      <td>8.152157</td>\n",
       "      <td>8.230157</td>\n",
       "      <td>8.308157</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.09300</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.18350</td>\n",
       "      <td>...</td>\n",
       "      <td>8.276310</td>\n",
       "      <td>0.173280</td>\n",
       "      <td>2.275186</td>\n",
       "      <td>0.851494</td>\n",
       "      <td>9.386155</td>\n",
       "      <td>0.758885</td>\n",
       "      <td>176.742981</td>\n",
       "      <td>18.830301</td>\n",
       "      <td>21.356354</td>\n",
       "      <td>77.678161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.949113</td>\n",
       "      <td>9.097113</td>\n",
       "      <td>7.144113</td>\n",
       "      <td>7.261113</td>\n",
       "      <td>7.339113</td>\n",
       "      <td>0.841</td>\n",
       "      <td>2.412</td>\n",
       "      <td>1.76975</td>\n",
       "      <td>1.8515</td>\n",
       "      <td>1.96300</td>\n",
       "      <td>...</td>\n",
       "      <td>7.276783</td>\n",
       "      <td>1.863201</td>\n",
       "      <td>2.862571</td>\n",
       "      <td>0.184102</td>\n",
       "      <td>8.638464</td>\n",
       "      <td>1.571577</td>\n",
       "      <td>179.939116</td>\n",
       "      <td>20.832203</td>\n",
       "      <td>24.728128</td>\n",
       "      <td>62.853726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.748672</td>\n",
       "      <td>6.570672</td>\n",
       "      <td>6.335672</td>\n",
       "      <td>6.374672</td>\n",
       "      <td>6.452672</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.945</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>...</td>\n",
       "      <td>6.295868</td>\n",
       "      <td>0.366653</td>\n",
       "      <td>3.619783</td>\n",
       "      <td>0.123984</td>\n",
       "      <td>7.809101</td>\n",
       "      <td>0.271956</td>\n",
       "      <td>177.960991</td>\n",
       "      <td>22.789082</td>\n",
       "      <td>28.267005</td>\n",
       "      <td>49.165149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.148312</td>\n",
       "      <td>6.139312</td>\n",
       "      <td>5.304312</td>\n",
       "      <td>5.344312</td>\n",
       "      <td>5.422312</td>\n",
       "      <td>0.456</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.58300</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.69400</td>\n",
       "      <td>...</td>\n",
       "      <td>5.389194</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>4.467160</td>\n",
       "      <td>0.829842</td>\n",
       "      <td>7.066920</td>\n",
       "      <td>0.950328</td>\n",
       "      <td>170.142572</td>\n",
       "      <td>24.075519</td>\n",
       "      <td>31.569053</td>\n",
       "      <td>38.085647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.305269</td>\n",
       "      <td>4.913269</td>\n",
       "      <td>4.483269</td>\n",
       "      <td>4.601269</td>\n",
       "      <td>4.679269</td>\n",
       "      <td>0.063</td>\n",
       "      <td>4.204</td>\n",
       "      <td>0.22250</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.34000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.455441</td>\n",
       "      <td>0.476914</td>\n",
       "      <td>5.346051</td>\n",
       "      <td>1.167715</td>\n",
       "      <td>6.401453</td>\n",
       "      <td>1.073830</td>\n",
       "      <td>152.459110</td>\n",
       "      <td>23.814710</td>\n",
       "      <td>34.222419</td>\n",
       "      <td>28.523370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.451657</td>\n",
       "      <td>4.730657</td>\n",
       "      <td>3.505657</td>\n",
       "      <td>3.583657</td>\n",
       "      <td>3.662657</td>\n",
       "      <td>0.196</td>\n",
       "      <td>1.567</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.92600</td>\n",
       "      <td>...</td>\n",
       "      <td>3.632458</td>\n",
       "      <td>0.718538</td>\n",
       "      <td>6.243681</td>\n",
       "      <td>0.579422</td>\n",
       "      <td>5.832720</td>\n",
       "      <td>0.739459</td>\n",
       "      <td>132.275503</td>\n",
       "      <td>22.678846</td>\n",
       "      <td>36.417217</td>\n",
       "      <td>21.186733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.203831</td>\n",
       "      <td>4.053831</td>\n",
       "      <td>2.750831</td>\n",
       "      <td>2.789831</td>\n",
       "      <td>2.867831</td>\n",
       "      <td>0.062</td>\n",
       "      <td>1.291</td>\n",
       "      <td>0.67700</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>0.82300</td>\n",
       "      <td>...</td>\n",
       "      <td>2.829137</td>\n",
       "      <td>0.768500</td>\n",
       "      <td>6.954910</td>\n",
       "      <td>0.514992</td>\n",
       "      <td>5.385818</td>\n",
       "      <td>0.624411</td>\n",
       "      <td>105.973970</td>\n",
       "      <td>19.676295</td>\n",
       "      <td>37.457983</td>\n",
       "      <td>15.237326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.027267</td>\n",
       "      <td>3.781733</td>\n",
       "      <td>2.140733</td>\n",
       "      <td>2.228733</td>\n",
       "      <td>2.316733</td>\n",
       "      <td>0.098</td>\n",
       "      <td>2.181</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.340320</td>\n",
       "      <td>0.252731</td>\n",
       "      <td>8.187181</td>\n",
       "      <td>0.267026</td>\n",
       "      <td>5.092194</td>\n",
       "      <td>1.040989</td>\n",
       "      <td>97.530497</td>\n",
       "      <td>19.152561</td>\n",
       "      <td>41.690810</td>\n",
       "      <td>11.917590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.671181</td>\n",
       "      <td>10.161181</td>\n",
       "      <td>7.935181</td>\n",
       "      <td>7.993181</td>\n",
       "      <td>8.081181</td>\n",
       "      <td>0.083</td>\n",
       "      <td>2.875</td>\n",
       "      <td>0.93850</td>\n",
       "      <td>1.9780</td>\n",
       "      <td>2.22000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.081428</td>\n",
       "      <td>1.284562</td>\n",
       "      <td>1.409414</td>\n",
       "      <td>0.141963</td>\n",
       "      <td>9.927181</td>\n",
       "      <td>1.765401</td>\n",
       "      <td>113.070636</td>\n",
       "      <td>11.390211</td>\n",
       "      <td>13.991436</td>\n",
       "      <td>80.224754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.263256</td>\n",
       "      <td>13.412256</td>\n",
       "      <td>6.967256</td>\n",
       "      <td>7.055256</td>\n",
       "      <td>7.143256</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.465</td>\n",
       "      <td>1.26700</td>\n",
       "      <td>1.5080</td>\n",
       "      <td>2.16500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.084112</td>\n",
       "      <td>1.598138</td>\n",
       "      <td>2.228719</td>\n",
       "      <td>1.720347</td>\n",
       "      <td>9.214386</td>\n",
       "      <td>0.802764</td>\n",
       "      <td>145.479837</td>\n",
       "      <td>15.788940</td>\n",
       "      <td>20.536088</td>\n",
       "      <td>65.273871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.434594</td>\n",
       "      <td>8.983594</td>\n",
       "      <td>5.922594</td>\n",
       "      <td>6.000594</td>\n",
       "      <td>6.118594</td>\n",
       "      <td>0.129</td>\n",
       "      <td>2.676</td>\n",
       "      <td>0.95650</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>1.21650</td>\n",
       "      <td>...</td>\n",
       "      <td>6.078358</td>\n",
       "      <td>1.070146</td>\n",
       "      <td>3.174059</td>\n",
       "      <td>0.302136</td>\n",
       "      <td>8.650889</td>\n",
       "      <td>0.415342</td>\n",
       "      <td>166.950352</td>\n",
       "      <td>19.296879</td>\n",
       "      <td>27.460784</td>\n",
       "      <td>52.583514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.381253</td>\n",
       "      <td>6.716253</td>\n",
       "      <td>4.953253</td>\n",
       "      <td>5.071253</td>\n",
       "      <td>5.217253</td>\n",
       "      <td>0.058</td>\n",
       "      <td>2.696</td>\n",
       "      <td>0.18400</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.40900</td>\n",
       "      <td>...</td>\n",
       "      <td>5.149076</td>\n",
       "      <td>0.611491</td>\n",
       "      <td>4.151188</td>\n",
       "      <td>0.281244</td>\n",
       "      <td>7.900347</td>\n",
       "      <td>0.164010</td>\n",
       "      <td>168.849632</td>\n",
       "      <td>21.373689</td>\n",
       "      <td>32.795470</td>\n",
       "      <td>40.677515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.803788</td>\n",
       "      <td>4.615788</td>\n",
       "      <td>3.921288</td>\n",
       "      <td>4.087788</td>\n",
       "      <td>4.293788</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.977</td>\n",
       "      <td>0.16550</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.29150</td>\n",
       "      <td>...</td>\n",
       "      <td>4.154690</td>\n",
       "      <td>0.868242</td>\n",
       "      <td>5.044552</td>\n",
       "      <td>0.598031</td>\n",
       "      <td>7.220664</td>\n",
       "      <td>1.792018</td>\n",
       "      <td>151.357911</td>\n",
       "      <td>20.963029</td>\n",
       "      <td>36.424235</td>\n",
       "      <td>29.998450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.003016</td>\n",
       "      <td>4.362016</td>\n",
       "      <td>2.839016</td>\n",
       "      <td>3.143016</td>\n",
       "      <td>3.835016</td>\n",
       "      <td>0.052</td>\n",
       "      <td>2.680</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.66500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.072905</td>\n",
       "      <td>0.526955</td>\n",
       "      <td>6.072220</td>\n",
       "      <td>0.138517</td>\n",
       "      <td>6.675317</td>\n",
       "      <td>0.280483</td>\n",
       "      <td>124.586564</td>\n",
       "      <td>18.654581</td>\n",
       "      <td>40.532977</td>\n",
       "      <td>20.523281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.744210</td>\n",
       "      <td>3.190210</td>\n",
       "      <td>2.160210</td>\n",
       "      <td>2.238210</td>\n",
       "      <td>2.277210</td>\n",
       "      <td>0.057</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2.15625</td>\n",
       "      <td>2.2795</td>\n",
       "      <td>2.38800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237277</td>\n",
       "      <td>2.285251</td>\n",
       "      <td>7.050085</td>\n",
       "      <td>1.623611</td>\n",
       "      <td>6.340799</td>\n",
       "      <td>0.925377</td>\n",
       "      <td>100.009549</td>\n",
       "      <td>15.772262</td>\n",
       "      <td>44.703377</td>\n",
       "      <td>14.186179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.141914</td>\n",
       "      <td>1.936914</td>\n",
       "      <td>1.311914</td>\n",
       "      <td>1.419914</td>\n",
       "      <td>1.497914</td>\n",
       "      <td>0.053</td>\n",
       "      <td>1.978</td>\n",
       "      <td>0.13800</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.23300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.421203</td>\n",
       "      <td>0.293636</td>\n",
       "      <td>8.058734</td>\n",
       "      <td>0.168584</td>\n",
       "      <td>6.071936</td>\n",
       "      <td>1.064750</td>\n",
       "      <td>69.542599</td>\n",
       "      <td>11.453754</td>\n",
       "      <td>48.931963</td>\n",
       "      <td>8.628998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AP1RTTA_min  AP1RTTA_max  AP1RTTA_25  AP1RTTA_50  AP1RTTA_75  \\\n",
       "0      9.192082    12.180082    9.807082   10.071082   10.364082   \n",
       "1      7.977884     9.831884    9.167884    9.196884    9.255884   \n",
       "2      8.095074     8.877074    8.451074    8.544074    8.642074   \n",
       "3      6.067432     7.991432    6.224432    6.302432    6.380432   \n",
       "4      4.905337     7.274337    6.063337    6.180337    6.258337   \n",
       "5      7.337477    10.073477    9.330477    9.418477    9.535477   \n",
       "6      6.385924     9.496924    8.558924    8.715924    8.773924   \n",
       "7      5.704424     8.903424    7.656424    7.773424    7.861424   \n",
       "8      3.962147     6.609147    5.114147    5.622147    6.130147   \n",
       "9      2.266863     5.977863    4.961863    5.185863    5.352863   \n",
       "10     6.561542    15.603542    8.005542    8.137542    9.089042   \n",
       "11     7.556247    11.579247    7.908247    7.986247    8.064247   \n",
       "12     6.019841     8.563841    7.186841    7.274841    7.391841   \n",
       "13     5.733167     9.927167    6.007167    6.085167    6.163167   \n",
       "14     4.431671    12.126671    5.582671    5.670671    5.738671   \n",
       "15     4.439721     5.611721    4.850721    4.937721    5.133721   \n",
       "16     2.760518     5.045518    4.459518    4.605518    4.722518   \n",
       "17     1.386816     8.343816    3.931316    4.082816    4.277816   \n",
       "18     8.123260    11.276260    8.434260    8.552260    8.610260   \n",
       "19     6.555143     8.625143    7.556143    7.634143    7.751143   \n",
       "20     5.752093    13.622093    6.552093    6.669093    6.786093   \n",
       "21     3.654699     6.736699    5.769699    5.857699    5.945699   \n",
       "22     1.167443     3.722443    3.214443    3.272443    3.331443   \n",
       "23     7.801157     8.514157    8.152157    8.230157    8.308157   \n",
       "24     6.949113     9.097113    7.144113    7.261113    7.339113   \n",
       "25     4.748672     6.570672    6.335672    6.374672    6.452672   \n",
       "26     5.148312     6.139312    5.304312    5.344312    5.422312   \n",
       "27     0.305269     4.913269    4.483269    4.601269    4.679269   \n",
       "28     2.451657     4.730657    3.505657    3.583657    3.662657   \n",
       "29     2.203831     4.053831    2.750831    2.789831    2.867831   \n",
       "30    -0.027267     3.781733    2.140733    2.228733    2.316733   \n",
       "31     7.671181    10.161181    7.935181    7.993181    8.081181   \n",
       "32     5.263256    13.412256    6.967256    7.055256    7.143256   \n",
       "33     5.434594     8.983594    5.922594    6.000594    6.118594   \n",
       "34     3.381253     6.716253    4.953253    5.071253    5.217253   \n",
       "35     2.803788     4.615788    3.921288    4.087788    4.293788   \n",
       "36     1.003016     4.362016    2.839016    3.143016    3.835016   \n",
       "37     1.744210     3.190210    2.160210    2.238210    2.277210   \n",
       "38     1.141914     1.936914    1.311914    1.419914    1.497914   \n",
       "\n",
       "    AP1STDEVA_min  AP1STDEVA_max  AP1STDEVA_25  AP1STDEVA_50  AP1STDEVA_75  \\\n",
       "0           0.124          2.368       0.90200        1.0420       1.15100   \n",
       "1           0.122          2.568       0.26200        0.2970       0.34000   \n",
       "2           0.000          2.189       0.12850        0.2080       0.43600   \n",
       "3           0.306          1.100       0.83100        0.8920       0.95200   \n",
       "4           0.085          2.070       0.27450        0.3640       0.45700   \n",
       "5           0.000          2.263       0.45600        0.5575       0.98950   \n",
       "6           0.234          2.606       0.75300        0.7930       0.84000   \n",
       "7           0.138          2.154       0.58200        0.6310       0.71100   \n",
       "8           0.067          3.159       0.26400        0.4690       0.72100   \n",
       "9           0.069          2.312       0.28900        0.3960       0.49500   \n",
       "10          0.000          3.385       0.17600        0.4490       1.70400   \n",
       "11          0.000          2.551       0.95800        1.0960       1.29300   \n",
       "12          0.053          3.135       0.98200        1.1280       1.36650   \n",
       "13          0.146          3.841       1.75000        1.8560       1.95700   \n",
       "14          0.085          4.276       0.35400        0.4840       0.76950   \n",
       "15          0.086          2.425       1.01200        1.1370       1.23900   \n",
       "16          0.000          1.968       0.10800        0.1480       0.26400   \n",
       "17          0.111          2.365       0.89900        1.0640       1.19850   \n",
       "18          0.444          3.063       1.20600        1.2940       1.36700   \n",
       "19          0.106          1.984       1.06975        1.1530       1.23600   \n",
       "20          0.057          3.289       0.14200        0.2270       0.44200   \n",
       "21          0.526          3.400       0.73850        0.8210       0.90350   \n",
       "22          0.106          3.341       0.75925        0.9040       1.17375   \n",
       "23          0.000          0.685       0.09300        0.1255       0.18350   \n",
       "24          0.841          2.412       1.76975        1.8515       1.96300   \n",
       "25          0.173          1.945       0.28100        0.3300       0.38500   \n",
       "26          0.456          2.238       0.58300        0.6340       0.69400   \n",
       "27          0.063          4.204       0.22250        0.2740       0.34000   \n",
       "28          0.196          1.567       0.58000        0.6940       0.92600   \n",
       "29          0.062          1.291       0.67700        0.7280       0.82300   \n",
       "30          0.098          2.181       0.22100        0.2730       0.33000   \n",
       "31          0.083          2.875       0.93850        1.9780       2.22000   \n",
       "32          0.000          4.465       1.26700        1.5080       2.16500   \n",
       "33          0.129          2.676       0.95650        1.0620       1.21650   \n",
       "34          0.058          2.696       0.18400        0.2660       0.40900   \n",
       "35          0.080          1.977       0.16550        0.2150       0.29150   \n",
       "36          0.052          2.680       0.18600        0.2670       0.66500   \n",
       "37          0.057          2.625       2.15625        2.2795       2.38800   \n",
       "38          0.053          1.978       0.13800        0.1750       0.23300   \n",
       "\n",
       "    ...  A_P_1_R_T_T_B  A_P_1_S_T_D_E_V_B  A_P_2_R_T_T_B  A_P_2_S_T_D_E_V_B  \\\n",
       "0   ...       9.860985           1.116149       6.076388           0.144283   \n",
       "1   ...       9.230879           0.424747       6.282222           0.510474   \n",
       "2   ...       8.431657           0.286670       6.606535           0.814729   \n",
       "3   ...       6.310012           0.893827       9.223969           0.799677   \n",
       "4   ...       6.049487           0.495289       9.939359           0.351382   \n",
       "5   ...       9.466362           0.705821       5.016889           1.094408   \n",
       "6   ...       8.600833           0.816597       5.375125           0.214925   \n",
       "7   ...       7.881820           0.618753       5.846336           1.605957   \n",
       "8   ...       5.195255           0.737088       8.582743           0.745549   \n",
       "9   ...       5.046985           0.474463       9.446476           0.147662   \n",
       "10  ...       8.166073           0.724311       4.177263           1.994493   \n",
       "11  ...       8.023966           1.174695       4.463235           0.798354   \n",
       "12  ...       7.136196           1.417582       4.929161           1.818303   \n",
       "13  ...       6.332151           1.955949       5.601575           0.646799   \n",
       "14  ...       5.661170           0.647979       6.422623           0.200123   \n",
       "15  ...       5.021261           1.174977       7.193062           0.311783   \n",
       "16  ...       4.420129           0.342574       8.055034           0.271413   \n",
       "17  ...       4.137761           1.023094       8.933132           0.292603   \n",
       "18  ...       8.546879           1.370246       3.127473           1.179244   \n",
       "19  ...       7.619604           1.195492       3.612889           0.340747   \n",
       "20  ...       6.748636           0.470111       4.219492           0.418374   \n",
       "21  ...       5.818171           0.916813       5.074313           0.889475   \n",
       "22  ...       3.138518           0.825395       8.550370           1.653500   \n",
       "23  ...       8.276310           0.173280       2.275186           0.851494   \n",
       "24  ...       7.276783           1.863201       2.862571           0.184102   \n",
       "25  ...       6.295868           0.366653       3.619783           0.123984   \n",
       "26  ...       5.389194           0.702222       4.467160           0.829842   \n",
       "27  ...       4.455441           0.476914       5.346051           1.167715   \n",
       "28  ...       3.632458           0.718538       6.243681           0.579422   \n",
       "29  ...       2.829137           0.768500       6.954910           0.514992   \n",
       "30  ...       2.340320           0.252731       8.187181           0.267026   \n",
       "31  ...       8.081428           1.284562       1.409414           0.141963   \n",
       "32  ...       7.084112           1.598138       2.228719           1.720347   \n",
       "33  ...       6.078358           1.070146       3.174059           0.302136   \n",
       "34  ...       5.149076           0.611491       4.151188           0.281244   \n",
       "35  ...       4.154690           0.868242       5.044552           0.598031   \n",
       "36  ...       3.072905           0.526955       6.072220           0.138517   \n",
       "37  ...       2.237277           2.285251       7.050085           1.623611   \n",
       "38  ...       1.421203           0.293636       8.058734           0.168584   \n",
       "\n",
       "    A_P_3_R_T_T_B  A_P_3_S_T_D_E_V_B  P_r_o_d_u_c_t___R_T_T_B  \\\n",
       "0        8.066601           0.136864               483.355744   \n",
       "1        7.077682           0.443328               410.422222   \n",
       "2        6.086084           0.390941               339.107072   \n",
       "3        2.234744           0.142254               130.063303   \n",
       "4        1.413777           0.984149                85.000437   \n",
       "5        8.184383           0.573785               388.937806   \n",
       "6        7.659420           0.891429               353.903410   \n",
       "7        6.046766           1.708095               278.653268   \n",
       "8        2.833381           0.200416               126.394474   \n",
       "9        2.166277           1.417366               103.272514   \n",
       "10       8.210008           1.630470               280.448788   \n",
       "11       7.589972           0.548664               271.805883   \n",
       "12       6.741920           0.204503               237.158760   \n",
       "13       5.823453           0.311985               206.599372   \n",
       "14       5.063792           1.113446               184.101597   \n",
       "15       4.234446           0.813111               152.932555   \n",
       "16       3.604764           0.331555               128.332748   \n",
       "17       3.166994           0.646008               117.163382   \n",
       "18       8.939227           0.805656               238.937435   \n",
       "19       8.073302           0.518209               222.247748   \n",
       "20       7.209123           0.205618               205.278209   \n",
       "21       6.428407           2.137917               190.009299   \n",
       "22       4.119504           0.355508               110.557948   \n",
       "23       9.386155           0.758885               176.742981   \n",
       "24       8.638464           1.571577               179.939116   \n",
       "25       7.809101           0.271956               177.960991   \n",
       "26       7.066920           0.950328               170.142572   \n",
       "27       6.401453           1.073830               152.459110   \n",
       "28       5.832720           0.739459               132.275503   \n",
       "29       5.385818           0.624411               105.973970   \n",
       "30       5.092194           1.040989                97.530497   \n",
       "31       9.927181           1.765401               113.070636   \n",
       "32       9.214386           0.802764               145.479837   \n",
       "33       8.650889           0.415342               166.950352   \n",
       "34       7.900347           0.164010               168.849632   \n",
       "35       7.220664           1.792018               151.357911   \n",
       "36       6.675317           0.280483               124.586564   \n",
       "37       6.340799           0.925377               100.009549   \n",
       "38       6.071936           1.064750                69.542599   \n",
       "\n",
       "    P_r_o_d_u_c_t___R_T_T_1_2_B  P_r_o_d_u_c_t___R_T_T_2_3  \\\n",
       "0                     59.918953                  49.015791   \n",
       "1                     57.989021                  44.462794   \n",
       "2                     55.709792                  40.214378   \n",
       "3                     58.203495                  20.613175   \n",
       "4                     60.123097                  14.053020   \n",
       "5                     47.508577                  41.073349   \n",
       "6                     46.230158                  41.169387   \n",
       "7                     46.081722                  35.352036   \n",
       "8                     44.610483                  24.318763   \n",
       "9                     47.676535                  20.462292   \n",
       "10                    34.116598                  34.306506   \n",
       "11                    35.813395                  33.875094   \n",
       "12                    35.176701                  33.231540   \n",
       "13                    35.469037                  32.633655   \n",
       "14                    36.361424                  32.519960   \n",
       "15                    36.116293                  30.458590   \n",
       "16                    35.603678                  29.036511   \n",
       "17                    36.994278                  28.292315   \n",
       "18                    26.730886                  27.955577   \n",
       "19                    27.528392                  29.168056   \n",
       "20                    28.475320                  30.419221   \n",
       "21                    29.523807                  32.652754   \n",
       "22                    26.834388                  35.223354   \n",
       "23                    18.830301                  21.356354   \n",
       "24                    20.832203                  24.728128   \n",
       "25                    22.789082                  28.267005   \n",
       "26                    24.075519                  31.569053   \n",
       "27                    23.814710                  34.222419   \n",
       "28                    22.678846                  36.417217   \n",
       "29                    19.676295                  37.457983   \n",
       "30                    19.152561                  41.690810   \n",
       "31                    11.390211                  13.991436   \n",
       "32                    15.788940                  20.536088   \n",
       "33                    19.296879                  27.460784   \n",
       "34                    21.373689                  32.795470   \n",
       "35                    20.963029                  36.424235   \n",
       "36                    18.654581                  40.532977   \n",
       "37                    15.772262                  44.703377   \n",
       "38                    11.453754                  48.931963   \n",
       "\n",
       "    P_r_o_d_u_c_t___R_T_T_1_3_B  \n",
       "0                     79.546866  \n",
       "1                     65.333477  \n",
       "2                     51.315477  \n",
       "3                     14.100569  \n",
       "4                      8.551983  \n",
       "5                     77.473724  \n",
       "6                     65.843040  \n",
       "7                     47.660037  \n",
       "8                     14.719288  \n",
       "9                     10.933095  \n",
       "10                    67.106783  \n",
       "11                    60.899231  \n",
       "12                    48.112409  \n",
       "13                    36.870458  \n",
       "14                    28.665773  \n",
       "15                    21.262297  \n",
       "16                    15.932252  \n",
       "17                    13.104033  \n",
       "18                    76.401680  \n",
       "19                    61.515882  \n",
       "20                    48.650218  \n",
       "21                    37.406612  \n",
       "22                    12.930698  \n",
       "23                    77.678161  \n",
       "24                    62.853726  \n",
       "25                    49.165149  \n",
       "26                    38.085647  \n",
       "27                    28.523370  \n",
       "28                    21.186733  \n",
       "29                    15.237326  \n",
       "30                    11.917590  \n",
       "31                    80.224754  \n",
       "32                    65.273871  \n",
       "33                    52.583514  \n",
       "34                    40.677515  \n",
       "35                    29.998450  \n",
       "36                    20.523281  \n",
       "37                    14.186179  \n",
       "38                     8.628998  \n",
       "\n",
       "[39 rows x 120 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking input data and output data by concatinating two dataframes\n",
    "input_data=grouped.iloc[:,2:] \n",
    "output_data = grouped.iloc[:, :2]\n",
    "first_df=grouped.iloc[:,2:] \n",
    "second_df=groupedd.iloc[:,2:] \n",
    "input_data = pd.concat([first_df, second_df], axis=1)\n",
    "output_data = grouped.iloc[:, :2]\n",
    "input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1eaaf6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=np.array(input_data.values)\n",
    "output_data=np.array(output_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "13f672d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 2)\n",
      "(39, 120)\n"
     ]
    }
   ],
   "source": [
    "X=input_data\n",
    "y=output_data\n",
    "print(output_data.shape)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b57485e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used standardscaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d5e2edd",
   "metadata": {},
   "source": [
    "**2. Test with Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3df86137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 6, 'n_estimators': 200}\n",
      "Mean Squared Error in meter: 1.066\n",
      "Root Mean Squared Error (RMSE) on new data in meter: 1.033\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 24.929\n",
      "R2 score is in percent: 72.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on new data with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "RF_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, RF_pred)\n",
    "print(\"Mean Squared Error in meter: {:.3f}\" .format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(y_test, RF_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in meter: {:.3f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.3f}'.format(mean_absolute_percentage_error(y_test,RF_pred)*100))\n",
    "\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(y_test, RF_pred)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "684b2947",
   "metadata": {},
   "source": [
    "**3. Testing with KNN Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "592f6eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value found by grid search: 3\n",
      "Mean Squared Error (MSE) on new data in m: 1.05\n",
      "Root Mean Squared Error (RMSE) on new data in m: 1.02\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 24.585\n",
      "R2 score is in percent: 72.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from math import sqrt\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "\n",
    "# Create a KNN model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Perform a grid search using cross-validation\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Print the best parameter value found by the grid search\n",
    "print('Best K value found by grid search:', grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# Get the predictions using the best K value\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "knn_pred = best_knn_model.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "mse = mean_squared_error(y_test, knn_pred)\n",
    "print('Mean Squared Error (MSE) on new data in m: {:.2f}'.format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(y_test, knn_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in m: {:.2f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.3f}'.format(mean_absolute_percentage_error(y_test,knn_pred)*100))\n",
    "\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(y_test, knn_pred)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae2b77b3",
   "metadata": {},
   "source": [
    "**4. Testing with DNN Regressor Model and Hyperparameter Tuning by using Keras Tuner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b43e67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=hp.Int('units_1', min_value=32, max_value=512, step=16), input_shape=(120,), activation='relu'))\n",
    "    model.add(keras.layers.Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    for i in range(hp.Int('num_hidden_layers', 1, 10)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i+2), min_value=32, max_value=512, step=16),\n",
    "                                 activation=hp.Choice('activation_' + str(i+2), values=['relu','sigmoid','tanh'])))\n",
    "        model.add(keras.layers.Dropout(hp.Float('dropout_' + str(i+2), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "        \n",
    "    model.add(keras.layers.Dense(units=2, activation='linear'))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "                        hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cb6d60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuner_test\\RTT_fingerprinting\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_test',\n",
    "    project_name='RTT_fingerprinting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7b34d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=200,\n",
    "           validation_data=(X_test,y_test) ,\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "64811e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner_test\\RTT_fingerprinting\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000002B74EB35900>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 400\n",
      "dropout_1: 0.30000000000000004\n",
      "num_hidden_layers: 1\n",
      "units_2: 272\n",
      "activation_2: sigmoid\n",
      "dropout_2: 0.0\n",
      "learning_rate: 0.01\n",
      "units_3: 368\n",
      "activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 496\n",
      "activation_4: relu\n",
      "dropout_4: 0.1\n",
      "units_5: 64\n",
      "activation_5: sigmoid\n",
      "dropout_5: 0.4\n",
      "units_6: 320\n",
      "activation_6: relu\n",
      "dropout_6: 0.1\n",
      "units_7: 80\n",
      "activation_7: sigmoid\n",
      "dropout_7: 0.0\n",
      "units_8: 128\n",
      "activation_8: tanh\n",
      "dropout_8: 0.1\n",
      "units_9: 384\n",
      "activation_9: sigmoid\n",
      "dropout_9: 0.0\n",
      "units_10: 496\n",
      "activation_10: tanh\n",
      "dropout_10: 0.2\n",
      "units_11: 48\n",
      "activation_11: sigmoid\n",
      "dropout_11: 0.0\n",
      "Score: 0.7750286857287089\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 288\n",
      "dropout_1: 0.1\n",
      "num_hidden_layers: 2\n",
      "units_2: 208\n",
      "activation_2: sigmoid\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.01\n",
      "units_3: 384\n",
      "activation_3: sigmoid\n",
      "dropout_3: 0.2\n",
      "units_4: 432\n",
      "activation_4: tanh\n",
      "dropout_4: 0.4\n",
      "units_5: 224\n",
      "activation_5: tanh\n",
      "dropout_5: 0.1\n",
      "Score: 0.9133182366689047\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 144\n",
      "dropout_1: 0.4\n",
      "num_hidden_layers: 1\n",
      "units_2: 48\n",
      "activation_2: sigmoid\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.001\n",
      "units_3: 512\n",
      "activation_3: relu\n",
      "dropout_3: 0.4\n",
      "units_4: 336\n",
      "activation_4: sigmoid\n",
      "dropout_4: 0.0\n",
      "units_5: 208\n",
      "activation_5: sigmoid\n",
      "dropout_5: 0.4\n",
      "units_6: 416\n",
      "activation_6: tanh\n",
      "dropout_6: 0.1\n",
      "units_7: 112\n",
      "activation_7: relu\n",
      "dropout_7: 0.1\n",
      "units_8: 32\n",
      "activation_8: relu\n",
      "dropout_8: 0.30000000000000004\n",
      "units_9: 144\n",
      "activation_9: relu\n",
      "dropout_9: 0.1\n",
      "units_10: 352\n",
      "activation_10: relu\n",
      "dropout_10: 0.4\n",
      "units_11: 448\n",
      "activation_11: relu\n",
      "dropout_11: 0.4\n",
      "Score: 0.9335622986157736\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 304\n",
      "dropout_1: 0.0\n",
      "num_hidden_layers: 7\n",
      "units_2: 176\n",
      "activation_2: relu\n",
      "dropout_2: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "units_3: 160\n",
      "activation_3: relu\n",
      "dropout_3: 0.4\n",
      "units_4: 368\n",
      "activation_4: relu\n",
      "dropout_4: 0.0\n",
      "units_5: 368\n",
      "activation_5: tanh\n",
      "dropout_5: 0.30000000000000004\n",
      "units_6: 416\n",
      "activation_6: relu\n",
      "dropout_6: 0.30000000000000004\n",
      "units_7: 144\n",
      "activation_7: sigmoid\n",
      "dropout_7: 0.2\n",
      "units_8: 320\n",
      "activation_8: relu\n",
      "dropout_8: 0.2\n",
      "units_9: 224\n",
      "activation_9: sigmoid\n",
      "dropout_9: 0.0\n",
      "units_10: 112\n",
      "activation_10: relu\n",
      "dropout_10: 0.1\n",
      "units_11: 48\n",
      "activation_11: relu\n",
      "dropout_11: 0.4\n",
      "Score: 1.0863179365793865\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 272\n",
      "dropout_1: 0.30000000000000004\n",
      "num_hidden_layers: 4\n",
      "units_2: 416\n",
      "activation_2: tanh\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.0001\n",
      "units_3: 32\n",
      "activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 32\n",
      "activation_4: relu\n",
      "dropout_4: 0.0\n",
      "units_5: 32\n",
      "activation_5: relu\n",
      "dropout_5: 0.0\n",
      "Score: 1.1212143500645955\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 336\n",
      "dropout_1: 0.4\n",
      "num_hidden_layers: 2\n",
      "units_2: 224\n",
      "activation_2: tanh\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.01\n",
      "units_3: 176\n",
      "activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 64\n",
      "activation_4: sigmoid\n",
      "dropout_4: 0.1\n",
      "units_5: 80\n",
      "activation_5: relu\n",
      "dropout_5: 0.0\n",
      "units_6: 160\n",
      "activation_6: sigmoid\n",
      "dropout_6: 0.0\n",
      "units_7: 512\n",
      "activation_7: tanh\n",
      "dropout_7: 0.4\n",
      "units_8: 336\n",
      "activation_8: tanh\n",
      "dropout_8: 0.0\n",
      "units_9: 272\n",
      "activation_9: sigmoid\n",
      "dropout_9: 0.4\n",
      "units_10: 128\n",
      "activation_10: relu\n",
      "dropout_10: 0.4\n",
      "units_11: 240\n",
      "activation_11: sigmoid\n",
      "dropout_11: 0.30000000000000004\n",
      "Score: 1.1546912789344788\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 432\n",
      "dropout_1: 0.2\n",
      "num_hidden_layers: 3\n",
      "units_2: 304\n",
      "activation_2: tanh\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.001\n",
      "units_3: 448\n",
      "activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 288\n",
      "activation_4: tanh\n",
      "dropout_4: 0.1\n",
      "units_5: 496\n",
      "activation_5: tanh\n",
      "dropout_5: 0.4\n",
      "units_6: 160\n",
      "activation_6: tanh\n",
      "dropout_6: 0.30000000000000004\n",
      "units_7: 464\n",
      "activation_7: tanh\n",
      "dropout_7: 0.2\n",
      "units_8: 64\n",
      "activation_8: tanh\n",
      "dropout_8: 0.30000000000000004\n",
      "units_9: 288\n",
      "activation_9: tanh\n",
      "dropout_9: 0.0\n",
      "units_10: 192\n",
      "activation_10: relu\n",
      "dropout_10: 0.1\n",
      "units_11: 352\n",
      "activation_11: tanh\n",
      "dropout_11: 0.4\n",
      "Score: 1.239575723807017\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 496\n",
      "dropout_1: 0.0\n",
      "num_hidden_layers: 2\n",
      "units_2: 192\n",
      "activation_2: tanh\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.0001\n",
      "units_3: 512\n",
      "activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 512\n",
      "activation_4: sigmoid\n",
      "dropout_4: 0.2\n",
      "units_5: 432\n",
      "activation_5: tanh\n",
      "dropout_5: 0.1\n",
      "units_6: 480\n",
      "activation_6: sigmoid\n",
      "dropout_6: 0.30000000000000004\n",
      "units_7: 512\n",
      "activation_7: relu\n",
      "dropout_7: 0.1\n",
      "units_8: 48\n",
      "activation_8: relu\n",
      "dropout_8: 0.2\n",
      "units_9: 512\n",
      "activation_9: sigmoid\n",
      "dropout_9: 0.4\n",
      "units_10: 192\n",
      "activation_10: sigmoid\n",
      "dropout_10: 0.1\n",
      "units_11: 80\n",
      "activation_11: sigmoid\n",
      "dropout_11: 0.1\n",
      "Score: 1.366973598798116\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 432\n",
      "dropout_1: 0.0\n",
      "num_hidden_layers: 3\n",
      "units_2: 384\n",
      "activation_2: relu\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.001\n",
      "units_3: 96\n",
      "activation_3: sigmoid\n",
      "dropout_3: 0.1\n",
      "units_4: 240\n",
      "activation_4: sigmoid\n",
      "dropout_4: 0.1\n",
      "units_5: 464\n",
      "activation_5: sigmoid\n",
      "dropout_5: 0.1\n",
      "units_6: 368\n",
      "activation_6: tanh\n",
      "dropout_6: 0.0\n",
      "units_7: 480\n",
      "activation_7: relu\n",
      "dropout_7: 0.2\n",
      "units_8: 448\n",
      "activation_8: relu\n",
      "dropout_8: 0.0\n",
      "units_9: 480\n",
      "activation_9: tanh\n",
      "dropout_9: 0.1\n",
      "units_10: 208\n",
      "activation_10: sigmoid\n",
      "dropout_10: 0.0\n",
      "units_11: 416\n",
      "activation_11: sigmoid\n",
      "dropout_11: 0.30000000000000004\n",
      "Score: 1.5199075937271118\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_1: 496\n",
      "dropout_1: 0.1\n",
      "num_hidden_layers: 7\n",
      "units_2: 240\n",
      "activation_2: tanh\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.0001\n",
      "units_3: 480\n",
      "activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 496\n",
      "activation_4: relu\n",
      "dropout_4: 0.1\n",
      "units_5: 464\n",
      "activation_5: relu\n",
      "dropout_5: 0.1\n",
      "units_6: 240\n",
      "activation_6: relu\n",
      "dropout_6: 0.4\n",
      "units_7: 480\n",
      "activation_7: tanh\n",
      "dropout_7: 0.0\n",
      "units_8: 144\n",
      "activation_8: tanh\n",
      "dropout_8: 0.4\n",
      "units_9: 32\n",
      "activation_9: tanh\n",
      "dropout_9: 0.1\n",
      "units_10: 400\n",
      "activation_10: relu\n",
      "dropout_10: 0.1\n",
      "units_11: 352\n",
      "activation_11: tanh\n",
      "dropout_11: 0.2\n",
      "Score: 1.5272841453552246\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "42e91bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 20.9739 - mse: 20.9739 - val_loss: 2.2402 - val_mse: 2.2402\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.0718 - mse: 3.0718 - val_loss: 4.3217 - val_mse: 4.3217\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.3419 - mse: 5.3419 - val_loss: 3.6377 - val_mse: 3.6377\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.7730 - mse: 3.7730 - val_loss: 2.2579 - val_mse: 2.2579\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6791 - mse: 1.6791 - val_loss: 1.8397 - val_mse: 1.8397\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8790 - mse: 0.8790 - val_loss: 2.0005 - val_mse: 2.0005\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0265 - mse: 1.0265 - val_loss: 1.8869 - val_mse: 1.8869\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9087 - mse: 0.9087 - val_loss: 1.5845 - val_mse: 1.5845\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8601 - mse: 0.8601 - val_loss: 1.2585 - val_mse: 1.2585\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7648 - mse: 0.7648 - val_loss: 1.1232 - val_mse: 1.1232\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7666 - mse: 0.7666 - val_loss: 1.1102 - val_mse: 1.1102\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 1.0886 - val_mse: 1.0886\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7856 - mse: 0.7856 - val_loss: 1.0077 - val_mse: 1.0077\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7437 - mse: 0.7437 - val_loss: 0.8818 - val_mse: 0.8818\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6245 - mse: 0.6245 - val_loss: 0.7906 - val_mse: 0.7906\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6817 - mse: 0.6817 - val_loss: 0.7739 - val_mse: 0.7739\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5968 - mse: 0.5968 - val_loss: 0.8113 - val_mse: 0.8113\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5407 - mse: 0.5407 - val_loss: 0.8759 - val_mse: 0.8759\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4602 - mse: 0.4602 - val_loss: 0.9607 - val_mse: 0.9607\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3944 - mse: 0.3944 - val_loss: 1.0387 - val_mse: 1.0387\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3737 - mse: 0.3737 - val_loss: 1.0771 - val_mse: 1.0771\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3589 - mse: 0.3589 - val_loss: 1.0748 - val_mse: 1.0748\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3372 - mse: 0.3372 - val_loss: 1.0495 - val_mse: 1.0495\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2648 - mse: 0.2648 - val_loss: 1.0209 - val_mse: 1.0209\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2583 - mse: 0.2583 - val_loss: 0.9987 - val_mse: 0.9987\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2163 - mse: 0.2163 - val_loss: 0.9794 - val_mse: 0.9794\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2334 - mse: 0.2334 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2379 - mse: 0.2379 - val_loss: 0.9294 - val_mse: 0.9294\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2202 - mse: 0.2202 - val_loss: 0.9249 - val_mse: 0.9249\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2815 - mse: 0.2815 - val_loss: 0.9500 - val_mse: 0.9500\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2044 - mse: 0.2044 - val_loss: 0.9679 - val_mse: 0.9679\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1809 - mse: 0.1809 - val_loss: 0.9667 - val_mse: 0.9667\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1626 - mse: 0.1626 - val_loss: 0.9622 - val_mse: 0.9622\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1925 - mse: 0.1925 - val_loss: 0.9639 - val_mse: 0.9639\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1077 - mse: 0.1077 - val_loss: 0.9595 - val_mse: 0.9595\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1209 - mse: 0.1209 - val_loss: 0.9529 - val_mse: 0.9529\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "dnn_model = tuner.hypermodel.build(best_hps)\n",
    "#best_model = tuner.get_best_models()[0]\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "n_epochs=500\n",
    "#history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=32, validation_split=0.2,callbacks=callbacks_list)\n",
    "#history = model.fit(X_train, y_train, epochs=n_epochs, bbatch_size=32, validation_split=0.2,callbacks=callbacks_list)\n",
    "history = dnn_model.fit(X_train, y_train, epochs=n_epochs, batch_size=32, validation_data=(X_test,y_test),callbacks=[keras.callbacks.EarlyStopping(patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6a30359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9529 - mse: 0.9529\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_mse = dnn_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "11ce2fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('DNN Model loss Plot')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend(['Train Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "42d26cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.0392313, 1.6168666],\n",
       "       [5.879202 , 6.484432 ],\n",
       "       [1.454984 , 7.2280188],\n",
       "       [2.9867556, 1.8118784],\n",
       "       [5.52092  , 6.961065 ],\n",
       "       [4.9390097, 1.8202083],\n",
       "       [1.5794966, 1.0215493],\n",
       "       [5.573147 , 6.6510825],\n",
       "       [5.4914074, 1.0750955],\n",
       "       [2.7919214, 7.42346  ],\n",
       "       [3.0131562, 7.403588 ],\n",
       "       [1.5750241, 7.4433336]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=dnn_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e9b9bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on new data in m: 0.95\n",
      "Root Mean Squared Error (RMSE) on new data in m: 0.98\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 20.76\n",
      "R2 score is in percent: 78.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error (MSE) on new data in m: {:.2f}'.format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(y_test, y_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in m: {:.2f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(y_test,y_pred)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(y_test, y_pred)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0a41234",
   "metadata": {},
   "source": [
    "**5. Random Regressor for DNN output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a194bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 6, 'n_estimators': 50}\n",
      "Mean Squared Error in meter: 0.165\n",
      "Root Mean Squared Error (RMSE) on new data in meter: 0.407\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 10.067\n",
      "R2 score is in percent: 95.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(y_pred, y_test)\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on new data with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "RF_pred = best_model.predict(y_pred)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, RF_pred)\n",
    "print(\"Mean Squared Error in meter: {:.3f}\" .format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(y_test, RF_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in meter: {:.3f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.3f}'.format(mean_absolute_percentage_error(y_test,RF_pred)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(y_test, RF_pred)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b759450",
   "metadata": {},
   "source": [
    "**6. KNN Regressor for DNN Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5ba1ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value found by grid search: 3\n",
      "Mean Squared Error (MSE) on new data in m: 0.68\n",
      "Root Mean Squared Error (RMSE) on new data in m: 0.82\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 20.91\n",
      "R2 score is in percent: 82.41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_neighbors': [3,5,7,9]}\n",
    "\n",
    "# Create a KNN model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Perform a grid search using cross-validation\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5)\n",
    "grid_search.fit(y_pred, y_test)\n",
    "\n",
    "# Print the best parameter value found by the grid search\n",
    "print('Best K value found by grid search:', grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# Get the predictions using the best K value\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "knn_pred = best_knn_model.predict(y_pred)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "mse = mean_squared_error(y_test, knn_pred)\n",
    "print('Mean Squared Error (MSE) on new data in m: {:.2f}'.format(mse))\n",
    "rmse=sqrt(mean_squared_error(y_test, knn_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in m: {:.2f}'.format(rmse))\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(y_test,knn_pred)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(y_test, knn_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2572f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for saving DNN Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "dnn_model.save('final_dnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "201927f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2b74ea35d20>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model('final_dnn_model.h5')\n",
    "loaded_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b117e91",
   "metadata": {},
   "source": [
    "**7. Validate the model with Unknown/online dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ea9f116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1RTT</th>\n",
       "      <th>AP1STDEV</th>\n",
       "      <th>AP1RSS</th>\n",
       "      <th>AP2RTT</th>\n",
       "      <th>AP2STDEV</th>\n",
       "      <th>AP2RSS</th>\n",
       "      <th>AP3RTT</th>\n",
       "      <th>AP3STDEV</th>\n",
       "      <th>AP3RSS</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>True_range1</th>\n",
       "      <th>True_range2</th>\n",
       "      <th>True_range3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.668149</td>\n",
       "      <td>1.209</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>6.055633</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-55</td>\n",
       "      <td>8.026878</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.727149</td>\n",
       "      <td>1.174</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>6.055633</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-55</td>\n",
       "      <td>8.055878</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.580149</td>\n",
       "      <td>1.205</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>6.055633</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-55</td>\n",
       "      <td>8.114878</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.697149</td>\n",
       "      <td>1.191</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>6.016633</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-55</td>\n",
       "      <td>7.977878</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.815149</td>\n",
       "      <td>1.128</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>6.055633</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-55</td>\n",
       "      <td>8.084878</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1.482527</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>8.242545</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-68</td>\n",
       "      <td>6.282632</td>\n",
       "      <td>0.907</td>\n",
       "      <td>-60</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>6.082763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.511527</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>8.242545</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-68</td>\n",
       "      <td>6.517632</td>\n",
       "      <td>0.874</td>\n",
       "      <td>-59</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>6.082763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1.580527</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>8.281545</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-68</td>\n",
       "      <td>6.722632</td>\n",
       "      <td>0.577</td>\n",
       "      <td>-56</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>6.082763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1.306527</td>\n",
       "      <td>1.239</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>8.359545</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-68</td>\n",
       "      <td>6.077632</td>\n",
       "      <td>1.011</td>\n",
       "      <td>-58</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>6.082763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1.970527</td>\n",
       "      <td>1.100</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>8.164545</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-69</td>\n",
       "      <td>5.755632</td>\n",
       "      <td>1.100</td>\n",
       "      <td>-62</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>6.082763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14277 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AP1RTT  AP1STDEV  AP1RSS    AP2RTT  AP2STDEV  AP2RSS    AP3RTT  \\\n",
       "0    9.668149     1.209   -67.0  6.055633     0.163     -55  8.026878   \n",
       "1    9.727149     1.174   -66.0  6.055633     0.162     -55  8.055878   \n",
       "2    9.580149     1.205   -66.0  6.055633     0.140     -55  8.114878   \n",
       "3    9.697149     1.191   -67.0  6.016633     0.126     -55  7.977878   \n",
       "4    9.815149     1.128   -66.0  6.055633     0.186     -55  8.084878   \n",
       "..        ...       ...     ...       ...       ...     ...       ...   \n",
       "218  1.482527     0.661   -53.0  8.242545     0.126     -68  6.282632   \n",
       "219  1.511527     0.165   -54.0  8.242545     0.141     -68  6.517632   \n",
       "220  1.580527     0.136   -54.0  8.281545     0.126     -68  6.722632   \n",
       "221  1.306527     1.239   -52.0  8.359545     0.065     -68  6.077632   \n",
       "222  1.970527     1.100   -49.0  8.164545     0.199     -69  5.755632   \n",
       "\n",
       "     AP3STDEV  AP3RSS  x  y   x1   y1   x2   y2   x3   y3  True_range1  \\\n",
       "0       0.140     -65  1  1  7.0  9.0  7.0  0.0  0.0  9.0    10.000000   \n",
       "1       0.150     -65  1  1  7.0  9.0  7.0  0.0  0.0  9.0    10.000000   \n",
       "2       0.125     -65  1  1  7.0  9.0  7.0  0.0  0.0  9.0    10.000000   \n",
       "3       0.165     -65  1  1  7.0  9.0  7.0  0.0  0.0  9.0    10.000000   \n",
       "4       0.145     -65  1  1  7.0  9.0  7.0  0.0  0.0  9.0    10.000000   \n",
       "..        ...     ... .. ..  ...  ...  ...  ...  ...  ...          ...   \n",
       "218     0.907     -60  6  8  7.0  9.0  7.0  0.0  0.0  9.0     1.414214   \n",
       "219     0.874     -59  6  8  7.0  9.0  7.0  0.0  0.0  9.0     1.414214   \n",
       "220     0.577     -56  6  8  7.0  9.0  7.0  0.0  0.0  9.0     1.414214   \n",
       "221     1.011     -58  6  8  7.0  9.0  7.0  0.0  0.0  9.0     1.414214   \n",
       "222     1.100     -62  6  8  7.0  9.0  7.0  0.0  0.0  9.0     1.414214   \n",
       "\n",
       "     True_range2  True_range3  \n",
       "0       6.082763     8.062258  \n",
       "1       6.082763     8.062258  \n",
       "2       6.082763     8.062258  \n",
       "3       6.082763     8.062258  \n",
       "4       6.082763     8.062258  \n",
       "..           ...          ...  \n",
       "218     8.062258     6.082763  \n",
       "219     8.062258     6.082763  \n",
       "220     8.062258     6.082763  \n",
       "221     8.062258     6.082763  \n",
       "222     8.062258     6.082763  \n",
       "\n",
       "[14277 rows x 20 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dfff=pd.read_csv('D:/testt.csv')\n",
    "data_folder = r'C:\\Users\\LILA\\Desktop\\RTT-FIngerprinting-with-offset\\RTT-Fingerprinting with offset\\Dataset\\Test_dataset\\With_offset'\n",
    "os.chdir(data_folder)\n",
    "extension='csv'\n",
    "\n",
    "all_filenames=[i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "combined_csv=pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "dfff=combined_csv\n",
    "dfff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1c11b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff.drop(['AP1RSS','AP2RSS','AP3RSS','True_range1','True_range2','True_range3','x1','x2','x3','y1','y2','y3'],axis=1,inplace=True)\n",
    "# dfff.drop(['AP1RSS','AP2RSS','AP3RSS'],axis=1,inplace=True)\n",
    "#dffff=dfff.assign(Product_RTT=dfff['AP1RTT']*dfff['AP2RTT']*dfff['AP3RTT'],Product_RTT12=dfff['AP1RTT']*dfff['AP2RTT'],Product_RTT23=dfff['AP2RTT']*dfff['AP3RTT'],Product_RTT13=dfff['AP1RTT']*dfff['AP3RTT'],square_RTT1=dfff['AP1RTT']*dfff['AP1RTT'],square_RTT2=dfff['AP2RTT']*dfff['AP2RTT'],square_RTT3=dfff['AP3RTT']*dfff['AP3RTT'])\n",
    "dffff=dfff.assign(Product_RTT=dfff['AP1RTT']*dfff['AP2RTT']*dfff['AP3RTT'],Product_RTT12=dfff['AP1RTT']*dfff['AP2RTT'],Product_RTT23=dfff['AP2RTT']*dfff['AP3RTT'],Product_RTT13=dfff['AP1RTT']*dfff['AP3RTT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f2a78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'x' and 'y'\n",
    "groups = dffff.groupby(['x', 'y'])\n",
    "\n",
    "# Split the groups into two separate dataframes\n",
    "df1 = pd.concat([group.iloc[:len(group) // 2] for _, group in groups])\n",
    "df2 = pd.concat([group.iloc[len(group) // 2:] for _, group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3ba7505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTT':'AP1RTTA','AP1STDEV':'AP1STDEVA','AP2RTT':'AP2RTTA','AP2STDEV':'AP2STDEVA','AP3RTT':'AP3RTTA','AP3STDEV':'AP3STDEVA','Product_RTT':'Product_RTTA','Product_RTT12':'Product_RTT12A','Product_RTT13':'Product_RTT13A','square_RTT1':'square_RTT1A','square_RTT2':'square_RTT2A','square_RTT3':'square_RTT3A'}\n",
    "df1.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "07fa77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTT':'AP1RTTB','AP1STDEV':'AP1STDEVB','AP2RTT':'AP2RTTB','AP2STDEV':'AP2STDEVB','AP3RTT':'AP3RTTB','AP3STDEV':'AP3STDEVB','Product_RTT':'Product_RTTB','Product_RTT12':'Product_RTT12B','Product_RTT13':'Product_RTT13B','square_RTT1':'square_RTT1B','square_RTT2':'square_RTT2B','square_RTT3':'square_RTT3B'}\n",
    "df2.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c308e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by x and y values, and calculate the mean of each group\n",
    "groupedd1 = df1.groupby(['x', 'y']).mean()\n",
    "groupedd2 = df2.groupby(['x', 'y']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "120fdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'x' and 'y', and calculate the minimum, maximum, 25th, 50th, and 75th percentiles for each column for local feature extractions\n",
    "grouped = df1.groupby(['x', 'y']).agg(['min', 'max', lambda x: np.percentile(x, q=25), lambda x: np.percentile(x, q=50), lambda x: np.percentile(x, q=75)])\n",
    "\n",
    "# Add the mean or average value of each column to the grouped dataframe\n",
    "grouped_mean = df1.groupby(['x', 'y']).mean()\n",
    "grouped = pd.concat([grouped, grouped_mean], axis=1)\n",
    "\n",
    "# Rename the columns and reset the index\n",
    "grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
    "grouped = grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1b1dd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'x' and 'y', and calculate the minimum, maximum, 25th, 50th, and 75th percentiles for each column for local feature extractions\n",
    "groupedd = df2.groupby(['x', 'y']).agg(['min', 'max', lambda x: np.percentile(x, q=25), lambda x: np.percentile(x, q=50), lambda x: np.percentile(x, q=75)])\n",
    "\n",
    "# # Add the mean or average value of each column to the grouped dataframe\n",
    "grouped_mean = df2.groupby(['x', 'y']).mean()\n",
    "groupedd = pd.concat([groupedd, grouped_mean], axis=1)\n",
    "\n",
    "# Rename the columns and reset the index\n",
    "groupedd.columns = ['_'.join(col).strip() for col in groupedd.columns.values]\n",
    "groupedd = groupedd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fbbf1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTTA_<lambda_0>': 'AP1RTTA_25','AP2RTTA_<lambda_0>': 'AP2RTTA_25','AP3RTTA_<lambda_0>': 'AP3RTTA_25',\n",
    "          'AP1RTTA_<lambda_1>': 'AP1RTTA_50','AP2RTTA_<lambda_1>': 'AP2RTTA_50','AP3RTTA_<lambda_1>': 'AP3RTTA_50',\n",
    "          'AP1RTTA_<lambda_2>': 'AP1RTTA_75','AP2RTTA_<lambda_2>': 'AP2RTTA_75','AP3RTTA_<lambda_2>': 'AP3RTTA_75',\n",
    "           \n",
    "             \n",
    "          'AP1STDEVA_<lambda_0>':'AP1STDEVA_25','AP2STDEVA_<lambda_0>':'AP2STDEVA_25','AP3STDEVA_<lambda_0>':'AP3STDEVA_25',\n",
    "          'AP1STDEVA_<lambda_1>':'AP1STDEVA_50','AP2STDEVA_<lambda_1>':'AP2STDEVA_50','AP3STDEVA_<lambda_1>':'AP3STDEVA_50',\n",
    "          'AP1STDEVA_<lambda_2>':'AP1STDEVA_75','AP2STDEVA_<lambda_2>':'AP2STDEVA_75','AP3STDEVA_<lambda_2>':'AP3STDEVA_75',\n",
    "          'A_P_1_R_T_T_A':'AP1RTTA_MEAN','A_P_2_R_T_T_A':'AP2RTTA_MEAN','A_P_3_R_T_T_A_A':'AP3RTTA_MEAN',\n",
    "          'A_P_1_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_2_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_3_S_T_D_E_V_A':'AP1STDEVA_MEAN'}\n",
    "grouped.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5fb1ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name={'AP1RTTB_<lambda_0>': 'AP1RTTB_25','AP2RTTB_<lambda_0>': 'AP2RTTB_25','AP3RTTB_<lambda_0>': 'AP3RTTB_25',\n",
    "          'AP1RTTB_<lambda_1>': 'AP1RTTB_50','AP2RTTB_<lambda_1>': 'AP2RTTB_50','AP3RTTB_<lambda_1>': 'AP3RTTB_50',\n",
    "          'AP1RTTB_<lambda_2>': 'AP1RTTB_75','AP2RTTB_<lambda_2>': 'AP2RTTB_75','AP3RTTB_<lambda_2>': 'AP3RTTB_75',\n",
    "           \n",
    "             \n",
    "          'AP1STDEVB_<lambda_0>':'AP1STDEVB_25','AP2STDEVB_<lambda_0>':'AP2STDEVB_25','AP3STDEVB_<lambda_0>':'AP3STDEVB_25',\n",
    "          'AP1STDEVB_<lambda_1>':'AP1STDEVB_50','AP2STDEVB_<lambda_1>':'AP2STDEVB_50','AP3STDEVB_<lambda_1>':'AP3STDEVB_50',\n",
    "          'AP1STDEVB_<lambda_2>':'AP1STDEVB_75','AP2STDEVB_<lambda_2>':'AP2STDEVB_75','AP3STDEVB_<lambda_2>':'AP3STDEVB_75',\n",
    "          'A_P_1_R_T_T_A':'AP1RTTA_MEAN','A_P_2_R_T_T_A':'AP2RTTA_MEAN','A_P_3_R_T_T_A_A':'AP3RTTA_MEAN',\n",
    "          'A_P_1_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_2_S_T_D_E_V_A':'AP1STDEVA_MEAN','A_P_3_S_T_D_E_V_A':'AP1STDEVA_MEAN'}\n",
    "groupedd.rename(columns=new_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cffd87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=grouped.iloc[:,2:] \n",
    "output_data = grouped.iloc[:, :2]\n",
    "first_df=grouped.iloc[:,2:] \n",
    "second_df=groupedd.iloc[:,2:] \n",
    "input_data = pd.concat([first_df, second_df], axis=1)\n",
    "output_data = grouped.iloc[:, :2]\n",
    "input_data=np.array(input_data.values)\n",
    "output_data=np.array(output_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "240dfa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 2)\n",
      "(37, 120)\n"
     ]
    }
   ],
   "source": [
    "XX=input_data\n",
    "yy=output_data\n",
    "print(output_data.shape)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "bef72809",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "XX= sc.fit_transform(XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b3fe7d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0241015, 1.0564634],\n",
       "       [1.0245867, 1.2512162],\n",
       "       [1.097249 , 2.0594437],\n",
       "       [1.5034928, 7.3881807],\n",
       "       [1.4969572, 7.280389 ],\n",
       "       [1.9424794, 1.1443121],\n",
       "       [1.5146435, 1.416301 ],\n",
       "       [2.2605517, 1.7920661],\n",
       "       [1.7124338, 7.5500345],\n",
       "       [1.856937 , 7.405486 ],\n",
       "       [3.1213107, 1.0554874],\n",
       "       [2.2879899, 1.5543051],\n",
       "       [2.893906 , 2.0492826],\n",
       "       [3.7368915, 4.6603546],\n",
       "       [3.0034697, 5.82613  ],\n",
       "       [3.186367 , 7.243889 ],\n",
       "       [3.3301485, 7.3202868],\n",
       "       [3.2742054, 7.3181953],\n",
       "       [4.496418 , 1.0861751],\n",
       "       [3.6749084, 1.5898135],\n",
       "       [4.1740036, 3.0400841],\n",
       "       [4.518325 , 3.9265141],\n",
       "       [4.025958 , 7.6861978],\n",
       "       [5.097088 , 1.0804415],\n",
       "       [5.699544 , 1.2842048],\n",
       "       [5.820712 , 3.6069837],\n",
       "       [5.492134 , 6.7276874],\n",
       "       [5.4178343, 6.808042 ],\n",
       "       [5.303301 , 6.8401575],\n",
       "       [5.33222  , 6.9843197],\n",
       "       [5.981982 , 1.226215 ],\n",
       "       [6.121722 , 1.7729598],\n",
       "       [5.6140566, 2.245439 ],\n",
       "       [6.021641 , 3.561375 ],\n",
       "       [6.1119986, 5.2717214],\n",
       "       [5.5753307, 6.725218 ],\n",
       "       [5.523389 , 6.9395876]], dtype=float32)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predd=loaded_model.predict(XX)\n",
    "y_predd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "62e0aca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on new data in mm: 0.30\n",
      "Root Mean Squared Error (RMSE) on new data in mm: 0.55\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 12.90\n",
      "R2 score is in percent: 93.70\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(yy, y_predd)\n",
    "print('Mean Squared Error (MSE) on new data in mm: {:.2f}'.format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(yy, y_predd)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in mm: {:.2f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(yy,y_predd)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(yy, y_predd)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3c1f0360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_x</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.024101</td>\n",
       "      <td>1.056463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.024587</td>\n",
       "      <td>1.251216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.097249</td>\n",
       "      <td>2.059444</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.503493</td>\n",
       "      <td>7.388181</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.496957</td>\n",
       "      <td>7.280389</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.942479</td>\n",
       "      <td>1.144312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.514644</td>\n",
       "      <td>1.416301</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.260552</td>\n",
       "      <td>1.792066</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.712434</td>\n",
       "      <td>7.550035</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.856937</td>\n",
       "      <td>7.405486</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.121311</td>\n",
       "      <td>1.055487</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.287990</td>\n",
       "      <td>1.554305</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.893906</td>\n",
       "      <td>2.049283</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.736892</td>\n",
       "      <td>4.660355</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.003470</td>\n",
       "      <td>5.826130</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.186367</td>\n",
       "      <td>7.243889</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.330148</td>\n",
       "      <td>7.320287</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.274205</td>\n",
       "      <td>7.318195</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.496418</td>\n",
       "      <td>1.086175</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.674908</td>\n",
       "      <td>1.589813</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.174004</td>\n",
       "      <td>3.040084</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.518325</td>\n",
       "      <td>3.926514</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.025958</td>\n",
       "      <td>7.686198</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.097088</td>\n",
       "      <td>1.080441</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.699544</td>\n",
       "      <td>1.284205</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.820712</td>\n",
       "      <td>3.606984</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.492134</td>\n",
       "      <td>6.727687</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.417834</td>\n",
       "      <td>6.808042</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.303301</td>\n",
       "      <td>6.840158</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.332220</td>\n",
       "      <td>6.984320</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.981982</td>\n",
       "      <td>1.226215</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.121722</td>\n",
       "      <td>1.772960</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.614057</td>\n",
       "      <td>2.245439</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.021641</td>\n",
       "      <td>3.561375</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.111999</td>\n",
       "      <td>5.271721</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.575331</td>\n",
       "      <td>6.725218</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.523389</td>\n",
       "      <td>6.939588</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_x  predicted_y  x  y\n",
       "0      1.024101     1.056463  1  1\n",
       "1      1.024587     1.251216  1  2\n",
       "2      1.097249     2.059444  1  3\n",
       "3      1.503493     7.388181  1  7\n",
       "4      1.496957     7.280389  1  8\n",
       "5      1.942479     1.144312  2  1\n",
       "6      1.514644     1.416301  2  2\n",
       "7      2.260552     1.792066  2  3\n",
       "8      1.712434     7.550035  2  7\n",
       "9      1.856937     7.405486  2  8\n",
       "10     3.121311     1.055487  3  1\n",
       "11     2.287990     1.554305  3  2\n",
       "12     2.893906     2.049283  3  3\n",
       "13     3.736892     4.660355  3  4\n",
       "14     3.003470     5.826130  3  5\n",
       "15     3.186367     7.243889  3  6\n",
       "16     3.330148     7.320287  3  7\n",
       "17     3.274205     7.318195  3  8\n",
       "18     4.496418     1.086175  4  1\n",
       "19     3.674908     1.589813  4  2\n",
       "20     4.174004     3.040084  4  3\n",
       "21     4.518325     3.926514  4  4\n",
       "22     4.025958     7.686198  4  8\n",
       "23     5.097088     1.080441  5  1\n",
       "24     5.699544     1.284205  5  2\n",
       "25     5.820712     3.606984  5  4\n",
       "26     5.492134     6.727687  5  5\n",
       "27     5.417834     6.808042  5  6\n",
       "28     5.303301     6.840158  5  7\n",
       "29     5.332220     6.984320  5  8\n",
       "30     5.981982     1.226215  6  1\n",
       "31     6.121722     1.772960  6  2\n",
       "32     5.614057     2.245439  6  3\n",
       "33     6.021641     3.561375  6  4\n",
       "34     6.111999     5.271721  6  5\n",
       "35     5.575331     6.725218  6  6\n",
       "36     5.523389     6.939588  6  8"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe for predicting values comparing with True values\n",
    "yy=pd.DataFrame(yy,columns=['x','y'])\n",
    "y_predd=pd.DataFrame(y_predd, columns=['predicted_x','predicted_y'])\n",
    "df_finall_dnn = pd.DataFrame()\n",
    "df_finall_dnn = pd.concat([y_predd, yy], axis=1)\n",
    "df_finall_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "22133d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finall_dnn.to_csv('output_data_dnn.csv', index=False) #for saving output value in csv file for reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d53520c",
   "metadata": {},
   "source": [
    "**8. Random Forest Regressor for final Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6d86c452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 8, 'n_estimators': 200}\n",
      "Mean Squared Error in meter: 0.067\n",
      "Root Mean Squared Error (RMSE) on new data in meter: 0.258\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 8.59\n",
      "R2 score is in percent: 98.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(y_predd,yy)\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on new data with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "RF_pred = best_model.predict(y_predd)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(yy, RF_pred)\n",
    "print(\"Mean Squared Error in meter: {:.3f}\" .format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(yy, RF_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in meter: {:.3f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(yy,RF_pred)*100))\n",
    "\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(yy, RF_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "dae7feb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_x</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.245</td>\n",
       "      <td>1.230</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.240</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.355</td>\n",
       "      <td>2.845</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.285</td>\n",
       "      <td>7.300</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.480</td>\n",
       "      <td>7.465</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.035</td>\n",
       "      <td>1.325</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.885</td>\n",
       "      <td>1.985</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.195</td>\n",
       "      <td>2.800</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.940</td>\n",
       "      <td>7.235</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.890</td>\n",
       "      <td>7.680</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.140</td>\n",
       "      <td>1.300</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.670</td>\n",
       "      <td>2.135</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.820</td>\n",
       "      <td>2.805</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.370</td>\n",
       "      <td>4.370</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.355</td>\n",
       "      <td>5.265</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.040</td>\n",
       "      <td>6.730</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.975</td>\n",
       "      <td>7.280</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.975</td>\n",
       "      <td>7.655</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.200</td>\n",
       "      <td>1.200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.970</td>\n",
       "      <td>1.975</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.100</td>\n",
       "      <td>3.265</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.060</td>\n",
       "      <td>3.850</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.525</td>\n",
       "      <td>7.745</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.965</td>\n",
       "      <td>1.230</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.215</td>\n",
       "      <td>1.740</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.200</td>\n",
       "      <td>3.880</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.145</td>\n",
       "      <td>5.390</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.075</td>\n",
       "      <td>6.185</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.065</td>\n",
       "      <td>6.865</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.100</td>\n",
       "      <td>7.745</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.670</td>\n",
       "      <td>1.310</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.760</td>\n",
       "      <td>2.145</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.715</td>\n",
       "      <td>2.675</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.640</td>\n",
       "      <td>3.875</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.745</td>\n",
       "      <td>5.040</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.705</td>\n",
       "      <td>5.865</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.730</td>\n",
       "      <td>7.685</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_x  predicted_y  x  y\n",
       "0         1.245        1.230  1  1\n",
       "1         1.240        1.750  1  2\n",
       "2         1.355        2.845  1  3\n",
       "3         1.285        7.300  1  7\n",
       "4         1.480        7.465  1  8\n",
       "5         2.035        1.325  2  1\n",
       "6         1.885        1.985  2  2\n",
       "7         2.195        2.800  2  3\n",
       "8         1.940        7.235  2  7\n",
       "9         1.890        7.680  2  8\n",
       "10        3.140        1.300  3  1\n",
       "11        2.670        2.135  3  2\n",
       "12        2.820        2.805  3  3\n",
       "13        3.370        4.370  3  4\n",
       "14        3.355        5.265  3  5\n",
       "15        3.040        6.730  3  6\n",
       "16        2.975        7.280  3  7\n",
       "17        2.975        7.655  3  8\n",
       "18        4.200        1.200  4  1\n",
       "19        3.970        1.975  4  2\n",
       "20        4.100        3.265  4  3\n",
       "21        4.060        3.850  4  4\n",
       "22        3.525        7.745  4  8\n",
       "23        4.965        1.230  5  1\n",
       "24        5.215        1.740  5  2\n",
       "25        5.200        3.880  5  4\n",
       "26        5.145        5.390  5  5\n",
       "27        5.075        6.185  5  6\n",
       "28        5.065        6.865  5  7\n",
       "29        5.100        7.745  5  8\n",
       "30        5.670        1.310  6  1\n",
       "31        5.760        2.145  6  2\n",
       "32        5.715        2.675  6  3\n",
       "33        5.640        3.875  6  4\n",
       "34        5.745        5.040  6  5\n",
       "35        5.705        5.865  6  6\n",
       "36        5.730        7.685  6  8"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy=pd.DataFrame(yy,columns=['x','y'])\n",
    "y_predd=pd.DataFrame(RF_pred, columns=['predicted_x','predicted_y'])\n",
    "df_finall = pd.DataFrame()\n",
    "df_finall = pd.concat([y_predd, yy], axis=1)\n",
    "df_finall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3619d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finall.to_csv('output_data_with_ex.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d93decd0",
   "metadata": {},
   "source": [
    "**9. KNN Regressor for Final Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1716108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value found by grid search: 3\n",
      "Mean Squared Error (MSE) on new data in m: 0.16\n",
      "Root Mean Squared Error (RMSE) on new data in m: 0.40\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 13.75\n",
      "R2 score is in percent: 95.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_neighbors': [3,5,7,9]}\n",
    "\n",
    "# Create a KNN model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Perform a grid search using cross-validation\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5)\n",
    "grid_search.fit(y_predd, yy)\n",
    "\n",
    "# Print the best parameter value found by the grid search\n",
    "print('Best K value found by grid search:', grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# Get the predictions using the best K value\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "knn_pred = best_knn_model.predict(y_predd)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "mse = mean_squared_error(yy, knn_pred)\n",
    "print('Mean Squared Error (MSE) on new data in m: {:.2f}'.format(mse))\n",
    "rmse=sqrt(mean_squared_error(yy, knn_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in m: {:.2f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(yy,knn_pred)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(yy, knn_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "db91b4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_x</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_x  predicted_y  x  y\n",
       "0      1.333333     1.333333  1  1\n",
       "1      1.333333     1.666667  1  2\n",
       "2      1.666667     2.666667  1  3\n",
       "3      1.333333     7.333333  1  7\n",
       "4      1.333333     7.666667  1  8\n",
       "5      1.666667     1.333333  2  1\n",
       "6      1.666667     1.666667  2  2\n",
       "7      2.666667     2.666667  2  3\n",
       "8      1.666667     7.666667  2  7\n",
       "9      1.666667     7.666667  2  8\n",
       "10     3.333333     1.333333  3  1\n",
       "11     2.666667     2.333333  3  2\n",
       "12     2.666667     2.666667  3  3\n",
       "13     3.333333     4.333333  3  4\n",
       "14     3.000000     5.000000  3  5\n",
       "15     3.000000     7.000000  3  6\n",
       "16     3.000000     7.000000  3  7\n",
       "17     3.333333     7.666667  3  8\n",
       "18     4.333333     1.333333  4  1\n",
       "19     3.666667     1.333333  4  2\n",
       "20     4.333333     3.666667  4  3\n",
       "21     3.666667     3.666667  4  4\n",
       "22     3.333333     7.666667  4  8\n",
       "23     5.333333     1.333333  5  1\n",
       "24     5.333333     1.333333  5  2\n",
       "25     5.000000     4.000000  5  4\n",
       "26     5.666667     5.333333  5  5\n",
       "27     5.333333     6.333333  5  6\n",
       "28     5.000000     7.000000  5  7\n",
       "29     5.333333     7.666667  5  8\n",
       "30     5.333333     1.333333  6  1\n",
       "31     5.666667     2.333333  6  2\n",
       "32     5.666667     2.333333  6  3\n",
       "33     5.666667     4.333333  6  4\n",
       "34     5.666667     5.333333  6  5\n",
       "35     5.333333     5.666667  6  6\n",
       "36     5.333333     7.666667  6  8"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy=pd.DataFrame(yy,columns=['x','y'])\n",
    "y_predd=pd.DataFrame(knn_pred, columns=['predicted_x','predicted_y'])\n",
    "df_finall_knn = pd.DataFrame()\n",
    "df_finall_knn = pd.concat([y_predd, yy], axis=1)\n",
    "df_finall_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a57609e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1789e",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9368ec49",
   "metadata": {},
   "source": [
    "**10. Random Forest Regressor only for validate dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "16a27359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 8, 'n_estimators': 100}\n",
      "Mean Squared Error in meter: 0.359\n",
      "Root Mean Squared Error (RMSE) on new data in meter: 0.599\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 14.66\n",
      "R2 score is in percent: 86.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(XX_train, yy_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on new data with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "RF_pred = best_model.predict(XX_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(yy_test, RF_pred)\n",
    "print(\"Mean Squared Error in meter: {:.3f}\" .format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(yy_test, RF_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in meter: {:.3f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(yy_test,RF_pred)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(yy_test, RF_pred)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46ad4f1f",
   "metadata": {},
   "source": [
    "**11. KNN Regressor only for validate dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b792ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value found by grid search: 5\n",
      "Mean Squared Error (MSE) on new data in m: 0.68\n",
      "Root Mean Squared Error (RMSE) on new data in m: 1.66\n",
      "Mean Absolute Percentage Error (MAPE) on new data in percentage is : 22.53\n",
      "R2 score is in percent: 75.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from math import sqrt\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "\n",
    "# Create a KNN model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Perform a grid search using cross-validation\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5)\n",
    "grid_search.fit(XX_train,yy_train)\n",
    "\n",
    "# Print the best parameter value found by the grid search\n",
    "print('Best K value found by grid search:', grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# Get the predictions using the best K value\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "knn_pred = best_knn_model.predict(XX_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "mse = mean_squared_error(yy_test, knn_pred)\n",
    "print('Mean Squared Error (MSE) on new data in m: {:.2f}'.format(mse))\n",
    "\n",
    "rmse=sqrt(mean_squared_error(y_test, knn_pred)) \n",
    "print('Root Mean Squared Error (RMSE) on new data in m: {:.2f}'.format(rmse))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('Mean Absolute Percentage Error (MAPE) on new data in percentage is : {:.2f}'.format(mean_absolute_percentage_error(yy_test,knn_pred)*100))\n",
    "\n",
    "print('R2 score is in percent: {:.2f}'.format(r2_score(yy_test, knn_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318f8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb72dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2b465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
